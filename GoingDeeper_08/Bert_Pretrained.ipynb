{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('aiffel': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4c90d37bfa0f6cee7230e0ca7c4fe4973eec2558a701045cc616562c2e060e72"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.2.0\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# tf version 및 gpu 확인\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "완료=3\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "prefix = 'ko_8000'\n",
    "vocab_size = 8000\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus_file} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰\n",
    "\n",
    "print(\"완료=3\")   # 완료메시지가 출력될 때까지 아무 출력내용이 없더라도 기다려 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/data'\n",
    "model_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/models'\n",
    "\n",
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_8000.model\")"
   ]
  },
  {
   "source": [
    "## Tokenizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " '블', '혼', '곳', '취', 'W', '럽', '엔', '험', '칭', '귀', '누', '겨', '암', '벌', '찰', '슬', '갈', '커', '씨', '’', '앙', '높', '웨', '슈', '‘', '첫', '뜻', '쳐', '침', '허', '즌', 'w', '죽', '효', '획', '볼', '널', '뉴', '응', '센', '났', '착', '큰', '락', '잡', '헌', '례', '희', '렸', '검', '폭', '득', '징', '움', '논', 'J', '%', '농', '섬', '걸', '캐', '홍', '럼', '틀', '풍', '느', '좌', '퇴', '택', '왔', '끝', '폴', '즉', '엘', '폐', '층', '될', '압', '줄', '픽', '헤', '덕', '윤', '싱', '맞', '먼', '념', '앞', '>', '찬', '맡', '긴', '<', '혁', '늘', '갖', '킨', '율', '써', '익', '〈', '〉', '턴', ']', '[', '릭', '잘', '램', '묘', '빈', '슨', '염', '링', '냈', '얼', '벨', '흥', '균', '억', '델', '닌', '앨', '객', '궁', '콘', '밝', '몇', '엄', '맹', '빌', '휘', '훈', '팔', '옥', '얻', '숙', '컵', '렌', '칸', '갔', '쇼', '“', '”', '텔', '칼', '됐', '므', '괴', '넘', '콜', '맥', '푸', '뷔', '좋', 'X', '몰', '붙', '덴', '핵', '찾', '혹', '낸', '흐', '둘', '빠', '떠', '켰', '템', 'x', '액', '혀', '샤', '컴', '릴', '몬', '뿐', '놓', '룹', '률', '쥐', 'z', '탑', '굴', '욕', '십', '끌', '떨', '힘', '잠', '롯', '싸', '죄', '칙', '갑', '핀', '벽', '척', '졸', '략', '춘', '풀', '몸', '먹', '눈', '맨', '켜', '잉', '끼', 'Y', '촌', '휴', '쳤', '잔', '컬', '홈', '벤', '칠', '렉', '밖', '大', '틴', '녹', '렇', '뛰', '몽', '뮤', '곤', '탁', '!', '륙', '폰', '털', '꾸', '혜', '멸', '탕', '둥', '겼', '밴', '웠', '솔', '겸', '혈', '돈', '딸', '톤', '렀', '혔', '셀', '쿄', '팅', '?', '낮', '넷', '컨', '홀', '앤', '님', '둔', '퓨', '냐', '」', '「', '윈', '텐', '랐', '겠', '욱', '롤', '톨', '탐', '떤', '헨', '꽃', '낙', '넓', '촉', '킬', '읍', '왜', '金', '셔', '콩', '렬', '붕', '山', '펜', '뇌', '랙', '옹', '덜', '슷', '흔', '융', '李', '옮', '섭', '=', '듬', '넣', '멘', '빛', '깨', '놀', '곧', '땅', '學', '킹', '닝', '룬', '헬', '팬', '딩', '쌍', '흑', '겐', '힌', '답', '켓', '챔', '롭', '룡', '값', '튜', '멤', '짓', '젤', '큐', '즘', '윌', '쉬', '쇄', '밤', '릉', '렵', '뢰', '웅', '닉', '흡', '튼', '젠', '씩', '납', '듀', '옛', '맺', '닥', '궤', '쉽', '짜', '랭', '숭', '듯', '+', '랫', '中', '文', '잃', '州', '숨', 'Z', '섯', 'j', '젝', '깊', '웃', '&', '롱', '빙', '꼬', '멜', '國', '멀', '쓴', '王', '캠', '펠', '웹', '핑', '큼', '잇', '즐', '끄', '텍', '믿', '뜨', '찍', '잎', '셰', '덤', ';', 'Q', '』', '『', '밍', '펼', '뷰', '짐', '틱', '빅', '돼', '뀌', '멕', '빨', '엽', '틸', '쇠', '짧', '삭', '곱', '子', '롬', '|', '校', '城', '첨', '폼', '東', '힐', '촬', '럴', '럭', '릿', '혐', '三', '道', 'q', '켈', '캘', '썼', '겪', '安', '곽', '낭', '랍', '딘', '옆', '밑', '켄', '氏', '쌓', '삶', '콤', '高', '흘', '人', '南', '벗', '뉘', '싶', '헝', '첩', '낳', '컷', '젊', '닐', '꿈', '냥', '빼', '옷', '랄', '天', '왼', '듣', '됨', '公', '얀', '읽', '닛', '톱', '냉', '셜', '°', '믹', '룩', '平', '寺', '엑', '픈', '事', '法', '벡', '낼', '섰', '숲', '퀴', '봄', '뒷', '엇', '띠', '書', '흰', '宗', '軍', '묵', '벼', '셋', '뤄', '튀', '븐', '붉', '잭', '쿨', '캄', '川', '元', '좀', '앗', '괄', '샌', '뿌', '義', '正', '끊', '뱅', '슴', '맛', '덮', '一', '씬', '넬', '팽', '녕', '륜', '찌', '–', '떻', '숫', '댄', '뱀', '府', '늬', '묻', '院', '長', '첼', '팩', '∼', '・', '짝', '둑', '웰', '石', '춤', 'é', '늄', '成', '쾌', '렴', '톰', '明', '쓸', '海', '셈', '탱', '뤼', '앵', '캔', '엠', '꼽', '깔', '陽', '뽑', '샘', '늦', '렐', '훨', '꺼', '밥', '닫', '西', '쫓', '光', '옌', '횡', '꼭', '君', '上', '太', '앉', '使', '郡', '팝', '德', '會', '原', '뼈', '륨', '地', '덩', '흉', '좁', '끈', '北', '겔', '武', '世', '끔', '家', '行', '部', '新', '봇', '렘', '本', '훗', '主', '꾼', '룸', 'ᆞ', '等', '깃', '룰', '뚜', '日', '都', '멍', '田', '윗', '神', '水', '韓', '덧', '춰', '펙', '랩', '門', '仁', '햄', '갤', '縣', '홋', '政', '퀘', '펴', '듭', '딕', '딜', '삽', '쿼', '꺾', '*', '龍', '生', '묶', '싼', '궐', '官', '륭', '經', '司', '탠', '퀸', '뮌', '윙', '無', '쌀', '꼴', '섞', '朴', '뉜', '겹', '里', '빗', '킴', '興', '눌', '훌', '띄', '趙', '×', '林', '긍', '첸', '슐', '펄', '洞', '忠', '녁', '밭', '셉', '깥', '돔', '相', '넌', 'а', '敎', '녔', '넥', '漢', '夫', '툰', '렛', '白', '民', '所', '永', '江', '聖', '낌', '五', '鄭', '펑', '臣', '和', '慶', '理', '빵', '돕', '馬', '깝', '史', '뿔', '張', '엉', '늑', '섹', '곰', '펀', '똑', '닷', '틈', '훼', '→', '全', 'の', '랴', '딱', '넨', '皇', '善', '컫', '前', '昌', '記', 'о', '흙', '힙', '朝', '굳', '將', '島', '帝', '툴', '갱', '定', '性', '핸', '心', '羅', '팡', '知', '尹', '化', '킥', '셸', '콰', '堂', '빚', 'и', '킷', '톡', '有', '겁', '껍', '之', '士', '풋', '小', '面', '맷', '닭', '벳', '崔', '十', '方', '겉', '京', '河', '松', '社', '쏘', '同', '뮬', '룽', '佛', '下', '時', '不', '淸', '굽', '멈', '古', '콥', '콕', '宮', '옵', '콧', 'α', '뇨', '봐', '푼', '通', '뻗', '代', '밸', '핫', '턱', '四', '信', '師', '딴', '럿', '年', '二', '떼', '꿀', '굿', '像', '렷', '탓', '퉁', '쯤', '論', '華', '죠', '後', '守', '닮', '劉', '樂', '쑤', '홉', '禮', '月', '祖', '八', '왈', '孝', '샹', '尙', '캡', '女', '굉', '줬', '權', '릎', '눅', '릇', '重', '圖', '쁜', '市', '붓', '뚫', '木', '字', 'е', 'н', '툼', '洪', '基', '칩', '黃', '싫', '낱', '物', '샬', '孫', '댐', '雲', '셨', '內', '陵', '놈', '立', '엣', '名', '業', '띤', '닿', '걷', '寧', '侯', '鎭', '듈', '吉', '낀', '合', '自', '科', '、', '廣', '驛', '헐', 'р', '삿', '判', '兵', '集', '갓', '흠', '派', '젖', '功', '殿', '柳', '順', '分', '봤', '監', '냄', '쩌', '衛', '宋', '承', '體', 'ー', '靑', '솟', '六', '春', '펌', '잊', '谷', '웬', '걱', '九', '周', '建', '議', '퐁', '景', '쉐', '※', '曹', '덟', '앱', '直', '옴', '솜', '•', '制', '돋', '곁', '美', '흩', '쥬', '쿤', '度', '톈', '둠', '슘', '者', '얄', '얇', '郞', '源', '굵', '英', '路', '륵', '긋', '쏟', '村', '얘', '福', 'á', '휩', '껴', '館', '멋', '짙', '宣', '見', '身', '左', '章', '萬', '팜', '탤', '花', '星', '貞', '꾀', '觀', '號', '렁', '#', '맵', '眞', '的', '$', '初', '節', 'с', '쯔', '밟', '濟', '꿔', '動', '治', '野', '훔', '덱', '泰', '뭉', '侍', '康', '副', '컸', '傳', '造', '챌', '캉', '왓', '뚝', '開', '根', '뤘', '外', '典', '音', '国', '壽', '떡', '令', '臺', 'к', '式', '쁘', '옐', '寶', '玉', '끓', '別', '應', '憲', '利', '햇', '{', '吳', '族', '奉', '思', '휠', 'い', '鮮', 'в', '뀐', '텀', '핍', '댓', 'ü', '后', '實', '命', '戰', '`', '씀', '語', '짱', '良', '御', 'ン', '唐', '弘', '修', '꽤', '保', '申', '촨', '잦', '맘', '횟', '智', '슭', '說', '浦', '親', 'л', '在', '作', '賢', '空', '錄', '阿', '픔', '形', '줌', '펫', '來', '塔', '省', '梁', '썬', '빔', '進', '位', '괘', '土', '敬', '앓', 'т', '老', '詩', '싯', '歌', '뒀', '벅', '밋', '工', '色', '界', '津', 'ا', '徐', '붐', '右', '엿', 'ο', '線', '參', '井', '秀', '碑', '갇', '얹', '땄', '눠', '七', '流', '延', '溪', '齋', '言', '風', '陳', '多', '깎', '딪', '護', '運', '멧', '샨', '間', '헥', '땃', '줘', '用', '팟', '如', '數', '藤', 'ö', '맑', '맏', 'ó', '常', 'ā', '藏', '口', '찐', 'μ', '슛', '벵', '玄', '任', '達', '꼈', '反', '텝', '楊', '몫', '許', '닦', '찔', '密', '甲', '場', '걀', '先', '鳳', '車', '옳', '對', '志', '깐', 'í', '亭', '뭇', '곶', '씌', '錫', '沈', '끗', '靈', '낫', '朱', '郎', '頭', '윅', '統', '쟈', '≪', '印', '≫', '夏', '禪', '얽', '佐', '랏', '熙', '麗', '烈', '姜', '팍', '出', '츄', '務', '뻔', '察', '團', '伯', '園', 'ν', '愛', '百', '識', '쭉', '榮', '器', '草', '關', '캅', '豊', '}', 'ι', '湖', '員', 'ς', '嘉', '現', '鄕', '튬', '儀', '귄', '諸', '뚱', '勝', '橋', '從', '意', '植', '晉', '商', '解', '墓', '■', '낚', '氣', '볍', '앰', '遠', 'ä', '祭', '鐵', '뜬', '○', '益', '千', '뱃', '容', '管', '뻐', '헛', '加', '竹', '伊', '起', '領', '坐', '챙', '쾰', '궈', '沙', '遺', '第', '팰', '찮', '調', '엮', '귤', '魏', '엥', '쩔', '恩', '秦', '處', '想', '機', '싹', '욘', '力', '非', 'ρ', '居', '雄', '―', 'し', '뾰', '報', '異', '畵', '핏', '렝', '뫼', '꿨', '泉', '惠', '次', 'ん', '캣', '柱', '鍾', '샐', '術', '黨', '火', 'β', '始', '我', 'τ', '支', '훙', '岩', '。', '崇', '뭄', '丁', '탬', '紀', '室', '쉴', '秋', '俊', '受', '得', '宇', '盧', '섀', 'か', '샀', '品', '웍', '廳', '昭', 'な', '資', '池', '깜', '類', '삐', '푹', 'う', '交', '얕', '낄', '넛', '果', '랬', '쿡', '싣', '舍', '뮈', '嚴', '營', '咸', '目', '育', '提', '돗', '꽂', '姓', '챈', 'ل', '曲', '늙', '系', '뜸', '局', '試', '總', 'ε', '믈', 'λ', '仲', '렙', '妃', '齊', '香', '@', '彦', '富', '卿', '圓', '尉', '少', 'ス', '顯', '能', '手', '波', '男', '表', '魚', '致', '꽝', '껏', '發', '댈', 'м', '群', '瑞', '냅', '慧', 'д', '吏', '숀', '戶', '防', '極', '角', '눔', '갚', '象', '農', '셴', 'た', '共', '母', '큘', '恭', '츰', '産', '情', '首', '쾨', '故', '署', '늪', '薩', '»', '촛', '짖', '邑', '즙', 'σ', 'と', '因', '췄', '蘇', '샵', '썩', '훤', '博', '☆', '짚', '尊', '樞', '탭', '虎', '覺', '陸', '찢', '△', '庵', '仙', 'й', '町', '結', '峰', '牧', '電', '갯', '듐', '쪼', '入', '房', '릅', 'イ', '몹', 'ル', '딧', '陰', '區', 'у', '半', '펭', '뿜', '獻', '蓮', '췌', '協', '倉', '屬', '淑', '閣', '녜', '빽', '完', '뜰', 'è', '域', '蔡', '뇽', '巖', '贊', '딥', '룻', '板', '겟', '範', '쁨', '슌', '괌', '굶', '溫', '翼', '菩', 'り', '普', '呂', '씻', '靖', '숍', '變', '～', '펩', '勳', '可', '쩐', '깁', '父', '넉', '乙', '連', '−', '쿰', 'る', '鶴', '맬', '哲', '엎', '銀', '丹', '퀄', '퀼', '샷', '邊', '僧', '死', '督', '뮐', '엡', '律', '燕', '핼', '学', '貴', '壇', '«', '船', '越', '祠', '台', '友', '淵', '뭐', '珍', '復', 'κ', '衆', '彌', '淳', '職', '載', '輔', '久', '벙', '—', '斗', '탔', '볶', '舊', '港', '롄', '\\\\', '藝', '近', '郭', '샴', '슝', 'ラ', '젯', '喜', '境', '莊', '쵸', '隆', '種', '赤', '奇', '잼', '껑', '벚', 'に', '具', '똥', '꿰', '뜯', '足', '윽', '允', '精', '臨', '썰', '衣', '땀', '澤', '純', '舞', '層', '特', '禹', '잣', '튠', '毛', '禁', '座', 'ま', '煥', '퓌', '球', '둡', '촘', '爲', '둬', '亞', '惡', '旨', '龜', '′', '素', '訓', '均', '맴', 'ら', '住', '낡', '뵈', '뽀', '촐', '陀', '雨', '奎', '쥘', '址', '廟', '洋', '멩', '쑨', 'リ', '儒', '꼼', '洙', '養', '劇', '條', '誠', '期', '轉', '텅', 'ト', '깅', '盛', '蘭', '閔', '魯', 'き', '備', '射', '隨', '괜', '멱', '浩', '私', '욤', '댕', '慈', '낯', '퓰', 'π', '聲', '丘', '内', '執', '€', '牛', '警', '좡', '今', '隊', '刑', '葉', '藩', '要', '念', '隱', '醫', '켐', '那', '放', '젓', '쥔', '以', '麻', '緣', '取', '킵', '列', '岳', '弼', '兼', 'γ', '淨', '뎀', '됩', '綱', '츨', '獨', '팎', '胡', '布', '質', '兒', '岡', '戦', '至', '桂', '聯', '팻', '±', '愼', '持', '謙', '훅', '檢', '改', '穆', '雙', 'は', '祿', '肅', '靜', '量', '캇', '觸', '羽', '製', '嶺', '希', '然', '若', '밧', '冠', 'ッ', '딤', 'く', '狀', '茂', '밈', '亂', 'ن', '封', '譜', '웜', '쉰', '圭', '洛', '由', 'お', '캥', '戒', '苦', '몄', '離', '띈', '釋', '쏠', '比', '錦', '約', '計', '랠', '聞', '助', '惱', '望', '賀', '썸', '퀀', '夢', '補', '銅', '于', '汝', 'я', 'ي', 'ク', '亨', '孔', '件', '飛', '珠', '뇰', '單', '甫', 'さ', '팥', 'δ', '帶', '卷', '欲', '兩', '委', '裵', '쑹', '칫', '剛', '末', '鏡', '뱌', 'ア', '摠', '考', '藥', '엌', '‧', '^', '왁', '客', '寅', '餘', '孟', '敏', '辛', '問', '屋', '樹', '杜', '易', '清', '짠', '尾', '恒', '鳥', '型', '留', 'à', '眼', '準', 'ī', 'て', '向', '誌', '쏜', '챠', '慕', '헴', 'η', '夷', '廷', '樓', '쐐', 'ç', '宰', '麟', '뭔', '퍽', '克', '役', '祥', '端', '윔', '쿵', '꽁', '威', '紅', '格', '滿', '環', '갸', '폈', '丞', '求', '黑', '솥', '技', '影', '会', '梅', '好', '晋', '葛', '釜', '鉉', 'г', '烏', '宅', '僉', '翰', 'あ', '究', '細', 'ь', '食', '쨌', 'ر', 'م', '厚', '己', 'و', '演', '叔', '辰', '摩', '넴', '乘', '講', '丙', '諫', '먀', '秉', '酒', '덥', '衡', '잖', '回', '啓', '選', '題', '騎', '깡', '뺏', '指', '曺', '證', '財', '乾', 'ち', '則', '쩍', '徳', '筆', '돛', '煩', '遊', 'É', 'â', 'タ', '增', '斷', '邱', '簡', '茶', '滅', '妙', '祐', '骨', '服', '話', '炳', '假', '籍', '敦', '未', '雅', '욜', '懿', '桓', '略', '젬', '句', '댁', 'こ', 'だ', '散', '宜', '条', '點', '콴', '昇', 'С', '邪', '늠', '雜', '裕', '딛', 'み', '軒', '銘', '얌', '扶', '輪', 'ы', '눕', '央', 'ú', '遼', '巨', '續', '革', '歸', 'シ', '뛴', '設', '刺', '襄', '鎬', '툭', '坊', '旗', '雪', '季', '擧', '硏', '策', '登', '盟', '뎅', '賜', '찻', 'つ', '休', '振', '曆', '丸', '征', '倭', '庶', '難', '칵', '震', 'ド', '庭', '繼', '固', '寬', '殷', '핌', '積', '廉', 'ч', '依', '契', '庫', '翁', '쑥', '貪', '卞', '勞', '病', '뮴', 'θ', 'が', '健', '놉', '앳', 'ί', 'ᄀ', 'を', '罪', '送', '읊', '簿', '峴', '最', '紙', '웁', '́', '俗', '旌', '感', '願', 'ω', '株', '欽', '版', '超', 'п', '洲', '옅', '姬', '贈', '際', '뺨', '힉', '刻', '坡', '寫', '皮', '⁄', '注', '童', '땐', '볕', '캬', 'も', '夜', '消', '燮', '뛸', 'υ', '詞', '賓', '邦', '★', '紫', 'ά', '翊', '쉘', '爾', '琴', '뺀', '懷', '漏', '僕', '再', '勢', '逸', 'す', '梵', '룀', 'カ', '晩', 'マ', '旅', '組', 'ᄋ', '区', '匡', '潤', '蒙', '諦', '횃', 'ό', '徒', '盤', '鑑', 'Δ', '←', '程', '蓋', '追', '介', '팸', 'れ', '深', '鼎', 'б', '序', 'え', '甘', '速', '過', '陶', 'よ', '歷', '썹', '쭈', '切', '鐘', '∙', '才', '県', '亮', '惟', '納', '엷', '磨', '巡', '站', '뀔', '봅', '料', '뽕', '凉', '止', '症', '퀵', 'د', '譯', '掌', '殺', '浮', '옙', '構', '팁', 'ジ', 'ロ', '配', '落', '壤', '芳', '샛', '推', '楚', '웸', 'š', 'з', '存', '毅', '刊', '熊', '꼰', '斯', '磁', '勇', 'ñ', '習', '背', 'ł', '꿇', '텃', '畿', '碩', '編', '置', '蘊', '갠', '숄', '尼', '虛', '於', '灣', '露', '땡', '춧', '泳', 'х', 'レ', '宿', '戸', '넵', '施', '頼', 'ê', '也', '而', '袁', '奴', '疏', '染', '維', '述', '活', '織', '씹', 'キ', '텡', '嬪', '街', '깬', '쉼', 'け', '項', 'フ', '率', '鹿', '失', '岐', '켤', 'ب', '祚', '迦', '냇', '뎌', '評', '깼', '奏', '當', '짤', '튿', '勒', '将', '崎', '뻘', '壁', '峯', '稅', '鳴', 'К', '輝', '差', '帥', '熱', '真', '〜', '專', '弟', '與', '告', '墳', '鬼', 'ß', '긁', '何', '干', '幸', '揚', '導', '米', '坪', '潭', '睦', 'ニ', '倫', '規', '墨', '爭', '步', 'コ', '堅', '模', '階', '刀', '援', '꽉', '찼', '휼', 'オ', '標', '닙', '뱉', '펨', 'ᄂ', 'っ', '冬', '舜', 'А', '移', '貢', '徽', '血', '賊', '蹟', '쇤', '撰', '獄', '紋', '綠', '引', '壬', '燈', '耶', '댑', '享', '決', '錢', '텟', '폄', '幕', '渡', '謝', '꺽', '눗', 'ᄅ', '案', '兪', '眠', '視', '貫', '깍', 'じ', '害', '蔚', '랗', '윳', '홑', '吾', '耳', '賞', '鼓', '其', '嗣', '葬', 'ô', '午', '奈', '弓', '愚', '照', '邉', 'ᄃ', '勤', '般', '輸', '撫', '青', '줍', '紹', '裝', '▲', '阮', '段', '솝', 'で', '秘', '胤', '辭', '힝', 'ᄆ', '豆', '솅', 'æ', 'ı', '候', '坂', '讀', '限', '얏', '戱', '浪', '伽', '庚', '歲', '쏴', '伏', '됭', '젼', '函', '操', '教', 'ナ', '栗', 'ū', 'φ', 'М', '豫', '査', '降', '웡', '喪', '魔', '算', '쌈', '쭤', '附', '뢴', '劍', '篇', '鴻', 'ə', 'や', '堤', '微', '忍', '授', '쎄', 'わ', '兄', '喆', '齡', '챕', 'ᅳ', '帖', '芝', '薛', '쫒', '諡', '£', 'П', '関', '頂', '符', '륀', 'ウ', '뎃', '創', '禧', '뜩', '傅', '壯', '材', '庄', '稷', '破', '鬪', '춥', '曾', '顔', '唱', '塚', '睿', '瞋', '障', '빴', '是', '班', '韻', '뎬', '幀', '級', '惑', '映', '蜀', '衍', '哀', '肉', '号', '廢', '彩', '接', '赫', '寒', 'س', '優', '閭', '뵤', '쩡', 'テ', '收', '脈', 'ø', 'ć', '伐', '脫', '舌', '還', '驪', '놨', '森', '檀', '須', 'В', 'ノ', 'ミ', '淮', '董', '郵', 'ш', '─', '冊', '꿩', '텁', 'バ', '箕', '萊', '談', '⟫', 'ャ', '徵', '油', '땜', '숱', '佑', '攝', '経', '묀', '찹', '岸', '救', '牙', '鍊', '̊', '包', '桃', '菴', '巴', '癡', '碧', '展', '請', '맙', '헵', '⟪', '味', '尺', '孤', '幹', '敵', '꿉', '튕', '給', '齒', '씽', '宝', '漁', '稱', '終', '讓', '退', '匠', '卯', '舟', '蔵', '黎', '놔', 'エ', 'チ', '融', '랸', 'ã', '去', '婦', '疑', '댜', '륄', '젱', '찜', 'サ', '逆', '떴', '卓', '潘', '볜', '헹', 'ع', '梨', '뤽', '뽐', '亥', '絶', '跋', '넋', '좇', 'έ', '寂', '잿', '橫', '番', '雍', '例', '崖', '換', '駐', '鷄', 'ひ', '唯', '実', '必', '陣', '빡', '쌌', '審', '蕭', 'ت', '羊', '숯', '컹', '仕', '湯', 'モ', '屯', '默', '县', '強', '腹', '썽', 'ュ', '價', '示', '옻', '잰', '햐', 'ᅵ', '柴', '旭', '覆', '賦', '鹽', '셍', '巫', '彭', '酉', '〕', '輿', '얗', '了', '婆', '戊', '毘', '菊', '著', '귈', '묄', '便', '培', '愍', '胎', '꿋', 'ィ', '慢', '爵', '뻣', '숏', '他', '낵', '潮', '탸', 'ē', '俱', '祀', '껌', 'ō', '〔', '댔', '볏', '앎', '흄', '貨', '푀', 'め', '築', '航', 'Б', 'י', 'グ', '妻', '朔', '澄', '禎', '遂', '酸', '丈', 'χ', 'ц', '巳', '濬', 'Р', '砲', '쌔', '広', '뷸', '녘', '括', '泥', '牟', '굼', '밌', '븀', '핥', 'Đ', '□', '停', '打', '折', '癸', '蔣', '覽', 'ư', 'ば', '牌', '탯', 'ょ', '輕', 'ズ', 'ム', '片', '헷', '底', '及', '듦', '줏', 'ه', '仇', '複', '軌', '툇', '占', '幡', '莫', '衙', '쳇', '万', '稿', 'ハ', '楽', 'プ', '祝', 'ή', '拳', '沃', '着', '蟲', '鎌', '炎', '탉', '戴', '整', '泗', 'ガ', '裁', '똘', 'メ', '肖', '駿', '챗', '券', '尚', '짊', '\\xad', 'ブ', '拓', '殊', 'ă', 'ˈ', 'ᄉ', '升', '召', '嫡', '庸', '槐', '沢', '突', '筵', '討', '乳', '擊', '菜', '휜', '佳', '尋', '店', '桐', '놋', '彰', '杉', '梧', '短', '쨩', '禍', '范', '鼻', '測', '曉', '朗', '枝', '鎮', '除', '덫', '坤', '就', '敍', 'Α', 'ろ', '係', '抗', '遷', '갬', 'ë', 'ː', '災', 'ᄇ', 'ゃ', '傑', '勅', '奭', '彈', '戌', '淡', '炯', '訴', 'И', '宙', '彫', '訪', '註', '냑', 'ύ', '凡', 'Н', '丑', '競', '賈', '辨', '溝', '藍', '幢', '態', '早', '갭', 'า', '胞', '荷', '被', '悲', '抄', '暴', '漆', '虞', 'ح', '壺', '槃', '汗', '耆', '額', '●', '穴', '雷', 'デ', '昊', '渾', '笠', 'Π', '乱', '昧', '苑', '荊', '待', '氷', '豪', '履', '甁', '遍', '郷', '魂', 'č', '乃', '禦', '綜', '綾', '艦', '閑', '隋', '괭', '눙', '욧', '仰', '幽', '探', '核', '穀', '卜', '各', '婚', '鈴', '塘', '毒', '炭', '粉', '鉢', '췬', 'Г', '∞', '垂', '扈', '賴', '껀', '젭', 'Σ', '犯', '遞', '拜', '눴', '沖', '珪', '采', '귓', '亡', '側', '呼', '権', '沼', '砂', '賣', '넙', 'ş', '█', '悟', '捨', '涅', '租', '頌', '앴', '첵', 'ふ', '濃', '荒', '費', '遇', '닳', 'ו', '儉', '迎', '뉠', '쁠', '쿱', '悅', '熟', '蕃', '궂', '쭝', 'å', '云', '企', '浚', '薰', '넜', 'Á', 'ж', '་', '投', '来', '耕', 'Т', '為', '総', '肥', '陜', '뺄', 'ゆ', '伴', '供', '宴', '按', '絲', '謹', '走', '긱', 'ぶ', '応', '卽', '庾', '效', '曰', '跡', 'そ', '卒', '哈', '浜', '鏞', '튤', '懸', '矢', '認', '뷜', 'ダ', '余', '卑', '寛', '床', '排', '擇', '晴', '璋', '網', 'ビ', '低', '急', '暗', '更', '盡', '黄', '넝', '숴', 'ق', '姫', '屠', '뵐', 'ی', '幼', '杖', '樣', '驗', '늉', '뚤', '콸', '億', '謀', '軸', '陟', '깟', '伝', '僞', '筑', '縛', '諱', '쥰', 'パ', '席', '攻', '晶', '섣', 'Д', 'ה', 'ف', 'せ', 'ど', 'ワ', '倍', '宏', '息', '窟', '鎔', '兆', '堯', '菌', '諭', 'ᄌ', '勿', '灘', '鄧', '헉', '冷', '彬', '獸', '舒', '馮', '喬', '忘', '眉', '緖', '豐', '飯', '쳅', '팹', '免', '含', '播', '洗', '燦', '瓦', '꾹', '垣', '奮', '招', '瀬', '謨', '겜', '†', 'ず', '圈', '烽', '迪', 'Л', 'ة', '銃', '쟝', '짬', 'ᄒ', '又', '戎', '緯', '훠', 'ᄏ', '塾', '駕', '鷹', '뎠', '솽', '펍', '【', '】', '束', '答', '買', '頓', '髮', '돤', 'ר', '壓', '奥', '蔭', '衝', '뭘', 'ج', 'ツ', '呪', '課', '頃', 'Κ', '党', '冥', '慰', '負', '껄', '벰', 'Ö', '↔', '憂', '昆', '텨', 'О', '浙', '蒲', '詳', '윕', '东', '充', '損', '뀜', '몐', '셤', '왠', 'ョ', '忽', '扇', '蜜', '劑', '强', '架', '索', '聚', '黒', '涉', '混', 'ร', '体', '渠', '犬', '篆', '險', '뗀', 'ð', 'ơ', 'ェ', '荀', '阪', '寄', '悌', '掛', '湘', '爐', '辦', 'ŋ', 'ほ', 'セ', '押', '詔', '괵', '듄', '셧', '숟', 'Φ', '沿', '綏', '韋', '뗏', '쬐', '팠', 'ï', 'ケ', '偏', '寇', '往', '揮', '樑', '訥', '阜', '샥', '텼', '⋅', 'び', '迷', '雀', '믐', '뷴', '쫄', 'î', 'ý', '瞻', '鑄', '빤', '푈', '伸', '嶽', '潛', '灌', '疾', '筒', '羲', '겅', '떳', '偉', '対', '戚', '拉', '糖', '訟', '顧', '맣', '왑', '此', '澈', '箭', '켠', 'ò', 'ệ', '付', '忌', '桑', '絃', '챘', '堀', '帽', '悼', '沒', '甄', '笑', '鉄', '镇', '雕', '닻', '씰', 'む', '傷', '屛', '幾', '溟', '練', '襲', '왐', '参', '綿', '諺', '適', '只', '姚', '晦', '満', '쏙', '챤', '≤', 'ね', '乞', '柔', '栢', '樊', '蒼', '観', '鑛', '끽', '숑', 'ś', 'א', '々', '꼿', 'ヶ', '갉', '뎁', '似', '广', '捕', '橘', '覇', '鵬', 'Ε', 'أ', 'ボ', '堡', '蘆', '蛇', '쪄', '刹', '郁', 'ž', '廊', '浅', '繫', '耽', '샅', '햅', '吹', '渓', '僖', '娘', '巾', '斤', '燧', '畫', '療', '线', '貝', '遮', '隣', '霞', 'э', 'ю', 'น', '冀', '脚', '誤', '꿍', '쥴', '톳', 'Å', 'ァ', '塵', '已', '看', '祉', '綬', '訣', '違', '넹', '뺑', '뻑', 'ᅡ', '旦', '游', '纂', '芸', '짼', '쳄', '휨', 'Š', 'ա', 'げ', '慮', '琉', '翔', 'ネ', '値', '劃', '斥', '暦', '瑜', '膺', 'ù', '借', '勸', '吐', '峻', '曜', '減', '燁', '皆', '窯', '膜', '零', '従', '循', '晟', '狄', '猛', '璿', '禄', '互', '圃', '幻', '燒', '獅', '瓊', '盜', '萱', '讚', '뭍', '債', '婢', '裏', '譚', '貿', '鳩', 'ế', '円', '屈', '歐', '漫', '皐', '趣', '鐸', '岑', '旋', '갛', 'ش', 'ヤ', '勉', '婁', '杏', '杓', '汀', '煙', '礙', '稽', '竿', '賤', '遣', '馨', '割', '卵', '塞', '変', '寵', '怪', '斬', '横', '狂', '珉', '避', '땔', '묽', '짰', '칡', 'ベ', '揆', '敞', '榜', '琳', '盆', '翠', '闕', '넸', '्', '恪', '挺', '擬', '旺', '棋', '睡', '翟', '裴', 'へ', 'ゅ', '亀', '抱', '湛', '粹', '솁', '쉔', '힛', 'ì', 'ń', '伎', '弐', '衿', '껫', '톄', 'ψ', 'ك', 'र', 'ソ', '姑', '弁', '怡', '昔', '杞', '畢', '確', '礪', '祈', '肇', '趾', '週', '預', 'ğ', 'Λ', 'ё', '誘', '閤', '륌', '폿', '徹', '殉', '遵', '邵', '閉', '飾', '빳', '쩨', '쳉', 'Ω', 'َ', '凝', '媛', '恐', '斎', '票', '辯', '閻', '켁', '斜', '熹', '画', '畜', '縱', '藻', '遜', '냘', '횔', 'ф', '個', '倒', '寿', '廻', '析', '沛', '炫', '窩', '腦', '説', '龐', '냔', 'ě', '♪', '串', '廬', '恵', '涼', '濱', '繁', '纏', '邸', '욥', '잽', '튈', 'ز', 'ᄎ', 'ᅩ', 'ḥ', '叢', '妄', '帳', '湜', '盈', '祗', '羌', '聰', '肩', '駒', '뒬', 'Μ', 'ξ', '„', '竺', '腸', '託', '録', '®', 'У', 'ב', '卦', '壞', '拔', '杭', '渭', '糧', '脂', '謁', '퉈', 'ạ', 'ピ', '奧', '峽', '快', '柏', '漸', '隸', '顕', '섐', '탰', 'ᄑ', '妓', '朋', '札', '棟', '檜', '渤', '珥', '畠', '秩', '詠', '鴨', '빻', 'Ü', 'і', '‚', 'ヒ', '凰', '峙', '灰', '猿', '瑩', '繡', '脩', '詮', '謠', '铁', 'ぎ', '圍', '崗', '敷', '溶', '脣', '苻', '醴', '隅', '좨', '쭐', 'מ', '场', '幣', '弥', '捷', '皓', '績', '誓', '陝', '녓', '씁', '윷', '죤', 'Γ', 'ご', '否', '彼', '悔', '滉', '狗', '窮', '褒', '輯', '鈞', '鎖', '뢸', 'ा', '什', '叉', '棺', '牒', '猶', '逢', '鄒', '銓', '閱', '▶', 'ぬ', '倂', '冶', '凶', '患', '液', '瀛', '疇', '筋', '薄', '裂', '阳', '냠', '찧', 'ζ', 'ṭ', 'ễ', '夕', '尤', '拘', '柄', '璽', '需', '響', '뗄', '∎', '勃', '戀', '楷', '歡', '溥', '軾', '鎰', '駅', '윰', '予', '伺', '採', '紗', '詹', '針', '飮', '黔', '깰', '멎', '틋', 'ܐ', '寸', '崙', '拾', '獲', '祇', '禿', '蠶', '遲', '鋼', '飡', '亦', '滋', '疫', '硬', '꽈', '뵙', '셩', '웩', '츤', 'ל', 'ა', 'ザ', 'ポ', '吸', '巢', '恨', '據', '暉', '楞', '电', '畏', '誕', 'ʼ', 'ก', 'ᄐ', '僚', '嵌', '椒', '爆', '瓚', '研', '篤', '胄', '螺', 'ʿ', 'ъ', '倻', '償', '哉', '爀', '狼', '窓', 'ง', '与', '你', '凌', '危', '坦', '塑', '弗', '弱', '械', '棲', '澗', '誼', '뜀', '솀', 'ɪ', 'Ο', 'อ', '♭', 'ぐ', '滄', '苗', '趺', '밉', '뺐', '‰', 'ゴ', '冕', '団', '旻', '瑛', '穡', '辺', '잴', '쫑', 'ώ', 'ᅮ', '偶', '厭', '当', '殘', '滑', '瓜', '竟', '臧', '醉', '隴', '믄', '웽', '쿈', '훑', 'Β', '図', '幅', '恋', '愧', '暎', '槍', '粒', '縮', '臥', '虹', '衰', '醮', '霖', '퍄', '§', 'Č', 'đ', 'ʻ', 'Ф', 'ი', 'ṣ', 'ギ', '凱', '叱', '幷', '批', '晃', '栄', '每', '気', '琦', '禾', '諍', '辟', '鞍', '韶', '驅', '쐈', '쾡', '홰', 'Θ', 'ม', 'ホ', '兎', '峨', '曼', '沆', '瀑', '燃', '罰', '聽', '腫', '腺', '莞', '鱗', '뷧', 'ط', '丕', '兢', '到', '媒', '悳', '掾', '旬', '曇', '汚', '涵', '牡', '猫', '璧', '郊', '髻', '鬱', '龙', 'З', 'べ', 'ヴ', '墩', '拍', '敗', '旣', '椿', '沔', '点', '籠', '継', '耀', '豹', '貸', '閩', '鞠', '쇳', '쟌', '刷', '哥', '懺', '昕', '楓', '痛', '矣', '礎', '竇', '虜', '鄴', '겊', '꽌', '垈', '尸', '慚', '楠', '絹']\n"
     ]
    }
   ],
   "source": [
    "# 특수 token 7개를 제외한 나머지 tokens 들\n",
    "vocab_list = []\n",
    "for id in range(7, len(vocab)):\n",
    "    if not vocab.is_unknown(id):\n",
    "        vocab_list.append(vocab.id_to_piece(id))\n",
    "print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# [CLS], tokens a, [SEP], tokens b, [SEP] 형태의 token 생성\n",
    "string_a = \"추적추적 비가 내리는 날이었어 그날은 왠지 손님이 많아 첫 번에 삼십 전 둘째번 오십 전 오랜만에 받아보는 십 전짜리 백통화 서푼에\"\n",
    "string_b = \"손바닥 위엔 기쁨의 눈물이 흘러 컬컬한 목에 모주 한잔을 적셔 몇 달 포 전부터 콜록거리는 아내 생각에 그토록 먹고 싶다던\"\n",
    "tokens_org = [\"[CLS]\"] + vocab.encode_as_pieces(string_a) + [\"[SEP]\"] + vocab.encode_as_pieces(string_b) + [\"[SEP]\"]\n",
    "print(tokens_org)"
   ]
  },
  {
   "source": [
    "## Data Preprocess & Mask"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "print(tokens_org)\n",
    "\n",
    "# 전체 token의 15% mask\n",
    "mask_cnt = int((len(tokens_org) - 3) * 0.15)\n",
    "mask_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 2, 3, 4] ['▁추', '적', '추', '적']\n[5, 6] ['▁비', '가']\n[7, 8] ['▁내', '리는']\n[9, 10, 11] ['▁날', '이었', '어']\n[12, 13, 14] ['▁그', '날', '은']\n[15, 16, 17] ['▁', '왠', '지']\n[18, 19, 20] ['▁손', '님', '이']\n[21, 22] ['▁많', '아']\n[23] ['▁첫']\n[24, 25] ['▁번', '에']\n[26, 27] ['▁삼', '십']\n[28] ['▁전']\n[29, 30, 31] ['▁둘', '째', '번']\n[32, 33] ['▁오', '십']\n[34] ['▁전']\n[35, 36, 37] ['▁오', '랜', '만에']\n[38, 39, 40] ['▁받아', '보', '는']\n[41] ['▁십']\n[42, 43, 44] ['▁전', '짜', '리']\n[45, 46, 47] ['▁백', '통', '화']\n[48, 49, 50] ['▁서', '푼', '에']\n[52, 53, 54] ['▁손', '바', '닥']\n[55, 56] ['▁위', '엔']\n[57, 58, 59] ['▁기', '쁨', '의']\n[60, 61] ['▁눈', '물이']\n[62, 63] ['▁흘', '러']\n[64, 65, 66] ['▁컬', '컬', '한']\n[67, 68] ['▁목', '에']\n[69, 70] ['▁모', '주']\n[71, 72, 73] ['▁한', '잔', '을']\n[74, 75] ['▁적', '셔']\n[76] ['▁몇']\n[77] ['▁달']\n[78] ['▁포']\n[79, 80] ['▁전', '부터']\n[81, 82, 83, 84] ['▁콜', '록', '거', '리는']\n[85] ['▁아내']\n[86, 87] ['▁생각', '에']\n[88, 89, 90] ['▁그', '토', '록']\n[91, 92] ['▁먹', '고']\n[93, 94, 95] ['▁싶', '다', '던']\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기 단위로 mask 하기 위해서 index 분할\n",
    "cand_idx = []  # word 단위의 index array\n",
    "for (i, token) in enumerate(tokens_org):\n",
    "    if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "        continue\n",
    "    if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
    "        cand_idx[-1].append(i)\n",
    "    else:\n",
    "        cand_idx.append([i])\n",
    "\n",
    "# 결과확인\n",
    "for cand in cand_idx:\n",
    "    print(cand, [tokens_org[i] for i in cand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[24, 25],\n",
       " [57, 58, 59],\n",
       " [32, 33],\n",
       " [64, 65, 66],\n",
       " [41],\n",
       " [79, 80],\n",
       " [52, 53, 54],\n",
       " [67, 68],\n",
       " [29, 30, 31],\n",
       " [91, 92],\n",
       " [23],\n",
       " [26, 27],\n",
       " [76],\n",
       " [42, 43, 44],\n",
       " [78],\n",
       " [60, 61],\n",
       " [38, 39, 40],\n",
       " [93, 94, 95],\n",
       " [9, 10, 11],\n",
       " [81, 82, 83, 84],\n",
       " [85],\n",
       " [12, 13, 14],\n",
       " [34],\n",
       " [71, 72, 73],\n",
       " [77],\n",
       " [45, 46, 47],\n",
       " [48, 49, 50],\n",
       " [28],\n",
       " [74, 75],\n",
       " [62, 63],\n",
       " [88, 89, 90],\n",
       " [5, 6],\n",
       " [35, 36, 37],\n",
       " [55, 56],\n",
       " [18, 19, 20],\n",
       " [86, 87],\n",
       " [7, 8],\n",
       " [15, 16, 17],\n",
       " [1, 2, 3, 4],\n",
       " [21, 22],\n",
       " [69, 70]]"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "# random mask를 위해서 순서를 섞음\n",
    "random.shuffle(cand_idx)\n",
    "cand_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokens_org\n['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n\ntokens\n['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '[MASK]', '[MASK]', '[MASK]', '▁삼', '십', '▁전', '▁둘', '째', '번', '[MASK]', '[MASK]', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '프', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '[MASK]', '[MASK]', '[MASK]', '▁눈', '물이', '▁흘', '러', '[MASK]', '[MASK]', '[MASK]', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# tokens가 mask되므로 재 실행을 위해서 넣어줌 (테스트용)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "mask_lms = []  # mask 된 값\n",
    "for index_set in cand_idx:\n",
    "    if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
    "          break\n",
    "    if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "          continue\n",
    "    dice = random.random()  # 0..1 사이의 확률 값\n",
    "\n",
    "    for index in index_set:\n",
    "        masked_token = None\n",
    "        if dice < 0.8:  # 80% replace with [MASK]\n",
    "            masked_token = \"[MASK]\"\n",
    "        elif dice < 0.9: # 10% keep original\n",
    "            masked_token = tokens[index]\n",
    "        else:  # 10% random word\n",
    "            masked_token = random.choice(vocab_list)\n",
    "        mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "        tokens[index] = masked_token\n",
    "\n",
    "print(\"tokens_org\")\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mask_idx   : [23, 24, 25, 32, 33, 41, 57, 58, 59, 64, 65, 66, 79, 80]\nmask_label : ['▁첫', '▁번', '에', '▁오', '십', '▁십', '▁기', '쁨', '의', '▁컬', '컬', '한', '▁전', '부터']\n"
     ]
    }
   ],
   "source": [
    "# 순서 정렬 및 mask_idx, mask_label 생성\n",
    "mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "print(\"mask_idx   :\", mask_idx)\n",
    "print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    \"\"\"\n",
    "    마스크 생성\n",
    "    :param tokens: tokens\n",
    "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
    "    :param vocab_list: vocab list (random token 용)\n",
    "    :return tokens: mask된 tokens\n",
    "    :return mask_idx: mask된 token의 index\n",
    "    :return mask_label: mask된 token의 원래 값\n",
    "    \"\"\"\n",
    "    # 단어 단위로 mask 하기 위해서 index 분할\n",
    "    cand_idx = []  # word 단위의 index array\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
    "            cand_idx[-1].append(i)\n",
    "        else:\n",
    "            cand_idx.append([i])\n",
    "    # random mask를 위해서 순서를 섞음\n",
    "    random.shuffle(cand_idx)\n",
    "\n",
    "    mask_lms = []  # mask 된 값\n",
    "    for index_set in cand_idx:\n",
    "        if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
    "            break\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "            continue\n",
    "        dice = random.random()  # 0..1 사이의 확률 값\n",
    "        for index in index_set:\n",
    "            masked_token = None\n",
    "            if dice < 0.8:  # 80% replace with [MASK]\n",
    "                masked_token = \"[MASK]\"\n",
    "            elif dice < 0.9: # 10% keep original\n",
    "                masked_token = tokens[index]\n",
    "            else:  # 10% random word\n",
    "                masked_token = random.choice(vocab_list)\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "    # mask_lms 정렬 후 mask_idx, mask_label 추출\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]  # mask된 token의 index\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]  # mask된 token의 원래 값\n",
    "\n",
    "    return tokens, mask_idx, mask_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokens_org\n['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n\ntokens\n['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '[MASK]', '[MASK]', '[MASK]', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '팹', '著', '內', '[SEP]', '▁손', '바', '닥', '[MASK]', '[MASK]', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '[MASK]', '[MASK]', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '[MASK]', '[MASK]', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n\nmask_idx   : [21, 22, 23, 48, 49, 50, 55, 56, 62, 63, 69, 70, 86, 87]\nmask_label : ['▁많', '아', '▁첫', '▁서', '푼', '에', '▁위', '엔', '▁흘', '러', '▁모', '주', '▁생각', '에']\n"
     ]
    }
   ],
   "source": [
    "# tokens가 mask되므로 재 실행을 위해서 넣어줌 (테스트용)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "tokens, mask_idx, mask_label = create_pretrain_mask(tokens, mask_cnt, vocab_list)\n",
    "\n",
    "print(\"tokens_org\")\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")\n",
    "print(tokens, \"\\n\")\n",
    "\n",
    "print(\"mask_idx   :\", mask_idx)\n",
    "print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "source": [
    "## NSP Pair"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\"\"추적추적 비가 내리는 날이었어\n",
    "그날은 왠지 손님이 많아\n",
    "첫 번에 삼십 전 둘째 번 오십 전\n",
    "오랜만에 받아보는 십 전짜리 백통화 서푼에\n",
    "손바닥 위엔 기쁨의 눈물이 흘러\n",
    "컬컬한 목에 모주 한잔을 적셔\n",
    "몇 달 포 전부터 콜록거리는 아내\n",
    "생각에 그토록 먹고 싶다던\n",
    "설렁탕 한 그릇을 이제는 살 수 있어\n",
    "집으로 돌아가는 길 난 문득 떠올라\n",
    "아내의 목소리가 거칠어만 가는 희박한 숨소리가\n",
    "오늘은 왠지 나가지 말라던 내 옆에 있어 달라던\n",
    "그리도 나가고 싶으면 일찍이라도 들어와 달라던\n",
    "아내의 간절한 목소리가 들려와\n",
    "나를 원망하듯 비는 점점 거세져\n",
    "싸늘히 식어가는 아내가 떠올라 걱정은 더해져\n",
    "난 몰라 오늘은 운수 좋은 날\n",
    "난 맨날 이렇게 살 수 있으면 얼마나 좋을까\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'],\n",
       " ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'],\n",
       " ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전']]"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "# 줄 단위로 tokenize\n",
    "doc = [vocab.encode_as_pieces(line) for line in string.split(\"\\n\")]\n",
    "doc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이\n",
    "n_test_seq = 64\n",
    "# 최소 길이\n",
    "min_seq = 8\n",
    "# [CLS], tokens_a, [SEB], tokens_b, [SEP]\n",
    "max_seq = n_test_seq - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "current_chunk: 5 62 [['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'], ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'], ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전'], ['▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']]\ntokens_a: 50 ['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에']\ntokens_b: 12 ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']\n\ncurrent_chunk: 6 71 [['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내'], ['▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던'], ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어'], ['▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라'], ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']]\ntokens_a: 55 ['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라']\ntokens_b: 16 ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']\n\ncurrent_chunk: 5 73 [['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던'], ['▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와'], ['▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']]\ntokens_a: 56 ['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져']\ntokens_b: 17 ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']\n\ncurrent_chunk: 2 22 [['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']]\ntokens_a: 9 ['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날']\ntokens_b: 13 ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']\n\n"
     ]
    }
   ],
   "source": [
    "current_chunk = []  # line 단위 tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)):  # doc 전체를 loop\n",
    "    current_chunk.append(doc[i])  # line 단위로 추가\n",
    "    current_length += len(doc[i])  # current_chunk의 token 수\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "        #######################################\n",
    "        # token a\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "          \n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        #######################################\n",
    "        print()\n",
    "\n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
    "    :param tokens_a: tokens A\n",
    "    :param tokens_b: tokens B\n",
    "    :param max_seq: 두 tokens 길이의 최대 값\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "current_chunk: 5 62 [['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'], ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'], ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전'], ['▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']]\nis_next: 0\ntokens_a: 28 ['▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']\ntokens_b: 33 ['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십']\n\ncurrent_chunk: 6 71 [['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내'], ['▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던'], ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어'], ['▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라'], ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']]\nis_next: 0\ntokens_a: 39 ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']\ntokens_b: 22 ['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내']\n\ncurrent_chunk: 5 73 [['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던'], ['▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와'], ['▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']]\nis_next: 1\ntokens_a: 17 ['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던']\ntokens_b: 44 ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '▁식', '어']\n\ncurrent_chunk: 2 22 [['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']]\nis_next: 1\ntokens_a: 9 ['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날']\ntokens_b: 13 ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']\n\n"
     ]
    }
   ],
   "source": [
    "current_chunk = []  # line 단위 tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)):  # doc 전체를 loop\n",
    "    current_chunk.append(doc[i])  # line 단위로 추가\n",
    "    current_length += len(doc[i])  # current_chunk의 token 수\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "        # token a\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "\n",
    "        #######################################\n",
    "        if random.random() < 0.5:  # 50% 확률로 swap\n",
    "            is_next = 0\n",
    "            tokens_t = tokens_a\n",
    "            tokens_a = tokens_b\n",
    "            tokens_b = tokens_t\n",
    "        else:\n",
    "            is_next = 1\n",
    "        # max_seq 보다 큰 경우 길이 조절\n",
    "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "        assert 0 < len(tokens_a)\n",
    "        assert 0 < len(tokens_b)\n",
    "\n",
    "        print(\"is_next:\", is_next)\n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        #######################################\n",
    "        print()\n",
    "\n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "current_chunk: 5 62 [['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어'], ['▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아'], ['▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전'], ['▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']]\nis_next: 0\ntokens_a: 12 ['▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러']\ntokens_b: 49 ['▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼']\ntokens: 64 ['[CLS]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '[SEP]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '▁번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '[SEP]']\nsegment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nmasked tokens: 64 ['[CLS]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '[SEP]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '[MASK]', '[MASK]', '[MASK]', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '[MASK]', '▁번', '에', '▁삼', '십', '가로', '[MASK]', '[MASK]', '▁번', '[MASK]', '[MASK]', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '[SEP]']\nmasked index: 9 [25, 26, 27, 36, 41, 42, 43, 45, 46]\nmasked label: 9 ['▁그', '날', '은', '▁첫', '▁전', '▁둘', '째', '▁오', '십']\n\ncurrent_chunk: 6 71 [['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내'], ['▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던'], ['▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어'], ['▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라'], ['▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가']]\nis_next: 1\ntokens_a: 12 ['▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔']\ntokens_b: 49 ['▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라', '▁아내', '의', '▁목', '소', '리가', '▁거']\ntokens: 64 ['[CLS]', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '[SEP]', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '▁살', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '▁길', '▁난', '▁문', '득', '▁떠', '올', '라', '▁아내', '의', '▁목', '소', '리가', '▁거', '[SEP]']\nsegment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nmasked tokens: 64 ['[CLS]', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '暴', '°', '[SEP]', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '[MASK]', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '[MASK]', '▁난', '▁문', '득', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁목', '소', '리가', '▁거', '[SEP]']\nmasked index: 9 [11, 12, 43, 50, 54, 55, 56, 57, 58]\nmasked label: 9 ['▁적', '셔', '▁살', '▁길', '▁떠', '올', '라', '▁아내', '의']\n\ncurrent_chunk: 5 73 [['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던'], ['▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와'], ['▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져']]\nis_next: 1\ntokens_a: 17 ['▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던']\ntokens_b: 44 ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '▁식', '어']\ntokens: 64 ['[CLS]', '▁오늘', '은', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '▁달', '라', '던', '[SEP]', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '▁식', '어', '[SEP]']\nsegment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nmasked tokens: 64 ['[CLS]', '[MASK]', '[MASK]', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '▁식', '어', '[SEP]']\nmasked index: 9 [1, 2, 15, 16, 17, 25, 26, 27, 28]\nmasked label: 9 ['▁오늘', '은', '▁달', '라', '던', '▁일', '찍', '이라', '도']\n\ncurrent_chunk: 2 22 [['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']]\nis_next: 0\ntokens_a: 13 ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까']\ntokens_b: 9 ['▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날']\ntokens: 25 ['[CLS]', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까', '[SEP]', '▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날', '[SEP]']\nsegment: 25 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nmasked tokens: 25 ['[CLS]', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까', '[SEP]', '▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날', '[SEP]']\nmasked index: 3 [7, 8, 15]\nmasked label: 3 ['▁있', '으면', '▁난']\n\n"
     ]
    }
   ],
   "source": [
    "instances = []\n",
    "current_chunk = []  # line 단위 tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)):  # doc 전체를 loop\n",
    "    current_chunk.append(doc[i])  # line 단위로 추가\n",
    "    current_length += len(doc[i])  # current_chunk의 token 수\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "        # token a\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "\n",
    "        if random.random() < 0.5:  # 50% 확률로 swap\n",
    "            is_next = 0\n",
    "            tokens_t = tokens_a\n",
    "            tokens_a = tokens_b\n",
    "            tokens_b = tokens_t\n",
    "        else:\n",
    "            is_next = 1\n",
    "        # max_seq 보다 큰 경우 길이 조절\n",
    "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "        assert 0 < len(tokens_a)\n",
    "        assert 0 < len(tokens_b)\n",
    "\n",
    "        print(\"is_next:\", is_next)\n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        #######################################\n",
    "        # tokens & aegment 생성\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "        segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "        print(\"tokens:\", len(tokens), tokens)\n",
    "        print(\"segment:\", len(segment), segment)\n",
    "        # mask\n",
    "        tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * 0.15), vocab_list)\n",
    "        print(\"masked tokens:\", len(tokens), tokens)\n",
    "        print(\"masked index:\", len(mask_idx), mask_idx)\n",
    "        print(\"masked label:\", len(mask_label), mask_label)\n",
    "\n",
    "        instance = {\n",
    "            \"tokens\": tokens,\n",
    "            \"segment\": segment,\n",
    "            \"is_next\": is_next,\n",
    "            \"mask_idx\": mask_idx,\n",
    "            \"mask_label\": mask_label\n",
    "        }\n",
    "        instances.append(instance)\n",
    "        #######################################\n",
    "        print()\n",
    "\n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'tokens': ['[CLS]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '[SEP]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '[MASK]', '[MASK]', '[MASK]', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '[MASK]', '▁번', '에', '▁삼', '십', '가로', '[MASK]', '[MASK]', '▁번', '[MASK]', '[MASK]', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [25, 26, 27, 36, 41, 42, 43, 45, 46], 'mask_label': ['▁그', '날', '은', '▁첫', '▁전', '▁둘', '째', '▁오', '십']}\n{'tokens': ['[CLS]', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '暴', '°', '[SEP]', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '[MASK]', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '[MASK]', '▁난', '▁문', '득', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁목', '소', '리가', '▁거', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [11, 12, 43, 50, 54, 55, 56, 57, 58], 'mask_label': ['▁적', '셔', '▁살', '▁길', '▁떠', '올', '라', '▁아내', '의']}\n{'tokens': ['[CLS]', '[MASK]', '[MASK]', '▁', '왠', '지', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '▁있어', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '▁거', '세', '져', '▁싸', '늘', '히', '▁식', '어', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 15, 16, 17, 25, 26, 27, 28], 'mask_label': ['▁오늘', '은', '▁달', '라', '던', '▁일', '찍', '이라', '도']}\n{'tokens': ['[CLS]', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까', '[SEP]', '▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [7, 8, 15], 'mask_label': ['▁있', '으면', '▁난']}\n"
     ]
    }
   ],
   "source": [
    "# 최종 데이터셋 결과 확인\n",
    "for instance in instances:\n",
    "    print(instance)"
   ]
  },
  {
   "source": [
    "## Next Sentence Predicction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    doc별 pretrain 데이터 생성\n",
    "    \"\"\"\n",
    "    # for CLS], [SEP], [SEP]\n",
    "    max_seq = n_seq - 3\n",
    "\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i])  # line\n",
    "        current_length += len(doc[i])\n",
    "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):\n",
    "            # token a\n",
    "            a_end = 1\n",
    "            if 1 < len(current_chunk):\n",
    "                a_end = random.randrange(1, len(current_chunk))\n",
    "            tokens_a = []\n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "            # token b\n",
    "            tokens_b = []\n",
    "            for j in range(a_end, len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "\n",
    "            if random.random() < 0.5:  # 50% 확률로 swap\n",
    "                is_next = 0\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1\n",
    "            # max_seq 보다 큰 경우 길이 조절\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "            assert 0 < len(tokens_a)\n",
    "            assert 0 < len(tokens_b)\n",
    "            # tokens & aegment 생성\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "            # mask\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
    "\n",
    "            instance = {\n",
    "                \"tokens\": tokens,\n",
    "                \"segment\": segment,\n",
    "                \"is_next\": is_next,\n",
    "                \"mask_idx\": mask_idx,\n",
    "                \"mask_label\": mask_label\n",
    "            }\n",
    "            instances.append(instance)\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'tokens': ['[CLS]', '▁번', '에', '▁삼', '십', '[MASK]', '▁둘', '째', 'え', '▁오', '십', '▁전', '▁오', '랜', '만에', '[MASK]', '[MASK]', '[MASK]', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [5, 8, 15, 16, 17, 36, 37, 38, 39], 'mask_label': ['▁전', '▁번', '▁받아', '보', '는', '▁눈', '물이', '▁흘', '러']}\n{'tokens': ['[CLS]', '[MASK]', '[MASK]', '▁몇', '▁달', '[MASK]', '▁전', '부터', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '탕', '▁한', '▁그', '릇', '을', '▁이', '제는', '[MASK]', '▁수', '▁있어', '▁집', '으로', '▁돌아', '가는', '[MASK]', '▁난', '▁문', '득', '▁떠', '올', '라', '[SEP]', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 5, 8, 9, 10, 11, 32, 39], 'mask_label': ['▁적', '셔', '▁포', '▁콜', '록', '거', '리는', '▁살', '▁길']}\n{'tokens': ['[CLS]', '에', '▁있어', '▁달', '라', '던', '▁그리', '도', '[MASK]', '[MASK]', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '▁달', '라', '던', '▁아내', '의', '▁간', '절', '한', '▁목', '소', '리가', '▁들', '려', '와', '[SEP]', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '썹', '숙', '촐', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '[MASK]', '[MASK]', '[MASK]', '▁더', '해', '져', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [2, 8, 9, 43, 44, 45, 57, 58, 59], 'mask_label': ['▁있어', '▁나가', '고', '▁거', '세', '져', '▁', '걱', '정은']}\n{'tokens': ['[CLS]', '▁난', '[MASK]', '[MASK]', '▁이렇게', '▁살', '[MASK]', '▁있', '으면', '▁얼마', '나', '▁좋', '을', '까', '[SEP]', '▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [2, 3, 6], 'mask_label': ['▁맨', '날', '▁수']}\n"
     ]
    }
   ],
   "source": [
    "instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "\n",
    "# 최종 데이터셋 결과 확인\n",
    "for instance in instances:\n",
    "    print(instance)"
   ]
  },
  {
   "source": [
    "## Dataset Finalizing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3957761"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "\n",
    "# line count 확인\n",
    "total = 0\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    for line in in_f:\n",
    "        total += 1\n",
    "\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/3957761 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c719bdd15064169b17f72483118f724"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "21 lines : ['▁지', '미', '▁카', '터']\n['▁제임스', '▁얼', '▁\"', '지', '미', '\"', '▁카', '터', '▁주', '니어', '(,', '▁192', '4', '년', '▁10', '월', '▁1', '일', '▁~', '▁)', '는', '▁민주', '당', '▁출신', '▁미국', '▁3', '9', '번째', '▁대통령', '▁(19', '7', '7', '년', '▁~', '▁1981', '년', ')', '이다', '.']\n['▁그는', '▁2002', '년', '▁말', '▁인', '권', '과', '▁중', '재', '▁역할', '에', '▁대한', '▁공', '로를', '▁인정', '받아', '▁노', '벨', '▁평화', '상을', '▁받', '게', '▁되었다', '.']\n\n14 lines : ['▁수학']\n['▁수학', '(', '數', '學', ',', '▁)', '은', '▁양', ',', '▁구조', ',', '▁공간', ',', '▁변화', ',', '▁미', '적', '분', '▁등의', '▁개념', '을', '▁다루', '는', '▁학', '문', '이다', '.', '▁현대', '▁수학', '은', '▁형식', '▁논', '리를', '▁이용', '해서', '▁공', '리로', '▁구성된', '▁추', '상', '적', '▁구조를', '▁연구', '하는', '▁학', '문', '으로', '▁여겨', '지', '기도', '▁한다', '.', '▁수학', '은', '▁그', '▁구조', '와', '▁발전', '▁과정', '에서는', '▁자연', '과학', '에', '▁속하는', '▁물리', '학을', '▁비롯한', '▁다른', '▁학', '문', '들과', '▁깊', '은', '▁연', '관을', '▁맺', '고', '▁있다', '.', '▁하지만', ',', '▁어느', '▁과학', '의', '▁분야', '들과', '는', '▁달리', ',', '▁자연', '계에서', '▁관측', '되지', '▁않는', '▁개념', '들에', '▁대해서', '까지', '▁이론', '을', '▁일반', '화', '▁및', '▁추', '상', '화', '시', '킬', '▁수', '▁있다는', '▁차', '이가', '▁있다고', '▁한다', '.', '▁수', '학자', '들은', '▁그러', '한', '▁개념', '들에', '▁대해서', '▁추', '측', '을', '▁하고', ',', '▁적', '절', '하게', '▁선택', '된', '▁정의', '와', '▁공', '리', '로부터', '의', '▁엄', '밀', '한', '▁연', '역을', '▁통해', '서', '▁추', '측', '들의', '▁진', '위를', '▁파', '악', '한다', '.']\n['▁수', '학의', '▁기초', '를', '▁확', '실', '히', '▁세', '우', '기', '▁위해', ',', '▁수', '리', '논', '리', '학과', '▁집합', '론', '이', '▁발전', '하였고', ',', '▁이와', '▁더불어', '▁범', '주', '론', '이', '▁최근', '에도', '▁발전', '되고', '▁있다', '.', '▁“', '근', '본', '▁위', '기', '”', '라는', '▁말', '은', '▁대', '략', '▁19', '00', '년', '에서', '▁1930', '년', '▁사이에', '▁일어난', ',', '▁수', '학의', '▁엄', '밀', '한', '▁기초', '에', '▁대한', '▁탐', '구를', '▁상징', '적으로', '▁보여', '주는', '▁말이다', '.', '▁수', '학의', '▁엄', '밀', '한', '▁기초', '에', '▁대한', '▁몇', '▁가지', '▁의견', '▁불', '일', '치는', '▁오늘날', '에도', '▁계속', '되고', '▁있다', '.', '▁수', '학의', '▁기초', '에', '▁대한', '▁위', '기는', '▁그', '▁당시', '▁수많은', '▁논', '쟁', '에', '▁의해', '▁촉', '발', '되었으며', ',', '▁그', '▁논', '쟁', '에는', '▁칸', '토', '어의', '▁집합', '론', '과', '▁브라', '우', '어', '-', '힐', '베', '르트', '▁논', '쟁', '이', '▁포함', '되었다', '.']\n\n4 lines : ['▁수학', '▁상', '수']\n['▁수학', '에서', '▁상', '수', '란', '▁그', '▁값', '이', '▁변', '하지', '▁않는', '▁불', '변', '량', '으로', ',', '▁변', '수의', '▁반대', '말', '이다', '.', '▁물리', '▁상', '수', '와는', '▁달리', ',', '▁수학', '▁상', '수는', '▁물리', '적', '▁측정', '과는', '▁상', '관', '없이', '▁정의', '된다', '.']\n['▁특정', '▁수학', '▁상', '수', ',', '▁예를', '▁들', '면', '▁골', '롬', '-', '딕', '맨', '▁상', '수', ',', '▁프랑', '세', '즈', '-', '로', '빈', '슨', '▁상', '수', ',', '▁formula', '_1', ',', '▁레', '비', '▁상', '수', '같은', '▁상', '수는', '▁다른', '▁수학', '상', '수', '▁또는', '▁함수', '와', '▁약', '한', '▁상', '관', '관', '계', '▁또는', '▁강한', '▁상', '관', '관', '계를', '▁갖', '는다', '.']\n\n10 lines : ['▁문학']\n['▁문학', '(', '文', '學', ')', '은', '▁언', '어를', '▁예술', '적', '▁표현', '의', '▁제', '재', '로', '▁삼', '아', '▁새로운', '▁의미', '를', '▁창', '출', '하여', ',', '▁인간', '과', '▁사회', '를', '▁진', '실', '되', '게', '▁묘사', '하는', '▁예술', '의', '▁하', '위', '분', '야', '이다', '.', '▁간', '단', '하게', '▁설명', '하면', ',', '▁언', '어를', '▁통해', '▁인간의', '▁삶', '을', '▁미', '적', '(', '美', '的', ')', '으로', '▁형', '상', '화', '한', '▁것이라고', '▁볼', '▁수', '▁있다', '.', '▁문학', '은', '▁원래', '▁문', '예', '(', '文', '藝', ')', '라고', '▁부', '르는', '▁것이', '▁', '옳', '으며', ',', '▁문', '학을', '▁학', '문', '의', '▁대상', '으로서', '▁탐', '구', '하는', '▁학', '문', '의', '▁명칭', '▁역시', '▁문', '예', '학', '이다', '.', '▁문', '예', '학', '은', '▁음악', '사', '학', ',', '▁미술', '사', '학', '▁등과', '▁함께', '▁예술', '학의', '▁핵', '심', '분', '야', '로서', '▁인', '문', '학의', '▁하', '위', '범', '주에', '▁포함', '된다', '.']\n['▁반', '영', '론', '적', '▁관', '점에', '▁의한', '▁감', '상은', '▁작품', '을', '▁창', '작', '된', '▁당시', '▁시대', '▁정', '황', '과', '▁연결', '시켜', '▁감', '상', '하는', '▁입', '장', '이고', ',', '▁내', '재', '적', '▁관', '점', '의', '▁감', '상은', '▁작품', '의', '▁형식', ',', '▁내용', '에', '▁국', '한', '하여', '▁감', '상', '하는', '▁것이다', '.', '▁표현', '론', '적', '▁관', '점', '의', '▁감', '상은', '▁작가', '의', '▁전기', '적', '▁사실', '과', '▁작품', '을', '▁연결', '시켜', '▁감', '상', '하는', '▁것이', '고', ',', '▁수용', '론', '적', '▁관', '점', '의', '▁감', '상은', '▁독', '자와', '▁작품', '을', '▁연결', '시켜', '▁감', '상', '하는', '▁것을', '▁말한다', '.']\n\n10 lines : ['▁나라', '▁목록']\n['▁이', '▁문', '서는', '▁나라', '▁목록', '이며', ',', '▁전', '▁세계', '▁20', '6', '개', '▁나라', '의', '▁각', '▁현', '황', '과', '▁주', '권', '▁승', '인', '▁정보를', '▁개', '요', '▁형태로', '▁나', '열', '하고', '▁있다', '.']\n['▁위', '▁목록', '에', '▁포함', '되지', '▁않은', '▁다음', '▁국가', '는', '▁몬', '테', '비', '데', '오', '▁협', '약', '의', '▁모든', '▁조건', '을', '▁만족', '하지', '▁못', '하거나', ',', '▁자주', '적이고', '▁독립', '적', '임을', '▁주장', '하지', '▁않는', '▁국가', '이다', '.']\n\n['▁화학']\n['▁화학', '(', '化', '學', ',', '▁)', '은', '▁물질', '의', '▁성', '질', ',', '▁조성', ',', '▁구조', ',', '▁변화', '▁및', '▁그', '에', '▁수', '반', '하는', '▁에너', '지의', '▁변', '화를', '▁연구', '하는', '▁자연', '과', '학의', '▁한', '▁분야', '이다', '.', '▁물리', '학', '도', '▁역시', '▁물질', '을', '▁다루', '는', '▁학', '문', '이지만', ',', '▁물리', '학', '이', '▁원', '소', '와', '▁화', '합', '물을', '▁모두', '▁포함한', '▁물', '체의', '▁운동', '과', '▁에너', '지', ',', '▁열', '적', '·', '전', '기', '적', '·', '광', '학적', '·', '기', '계', '적', '▁속', '성을', '▁다루', '고', '▁이러한', '▁현', '상', '으로부터', '▁통일', '된', '▁이론', '을', '▁구축', '하려는', '▁것', '과는', '▁달리', '▁화학', '에서는', '▁물질', '▁자', '체를', '▁연구', '▁대상으로', '▁한다', '.', '▁화학', '은', '▁이미', '▁존재', '하는', '▁물질', '을', '▁이용하여', '▁특', '정한', '▁목', '적', '에', '▁맞', '는', '▁새로운', '▁물질', '을', '▁합', '성', '하는', '▁길', '을', '▁제공', '하며', ',', '▁이는', '▁농', '작', '물의', '▁증', '산', ',', '▁질', '병', '의', '▁치료', '▁및', '▁예', '방', ',', '▁에너', '지', '▁효', '율', '▁증', '대', ',', '▁환경', '오', '염', '▁감소', '▁등', '▁여러', '▁가지', '▁이', '점을', '▁제공', '한다', '.']\n['▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '해', '낸', '▁화', '합', '물을', '▁뜻', '하였으나', '▁지금', '은', '▁유', '기', '▁화', '합', '물의', '▁범', '위가', '▁크게', '▁넓', '어져', '▁탄', '소', '▁사', '슬', '▁또는', '▁탄', '소', '▁고', '리를', '▁가진', '▁모든', '▁화', '합', '물을', '▁뜻', '한다', '.', '▁유', '기', '화', '학의', '▁오', '랜', '▁관', '심', '사는', '▁유', '기', '▁화', '합', '물의', '▁합', '성', '▁메', '커', '니', '즘', '이다', '.', '▁현', '대에', '▁들어', '서', '▁핵', '자', '기', '▁공', '명', '법', '과', '▁X', '선', '▁결정', '학', '▁등이', '▁개발', '되어', '▁유', '기', '▁화', '합', '물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.']\n"
     ]
    }
   ],
   "source": [
    "# 위키가 주제별로 잘 나눠지는지 여부 확인\n",
    "count = 5\n",
    "\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = []  # 단락 단위로 문서 저장\n",
    "    for line in tqdm(in_f, total=total):\n",
    "        line = line.strip()\n",
    "        if line == \"\":  # line이 빈줄 일 경우 (새로운 단락을 의미 함)\n",
    "            if 0 < len(doc):\n",
    "                if 0 < count:\n",
    "                    count -= 1\n",
    "                    print(len(doc), \"lines :\", doc[0])\n",
    "                    print(doc[1])\n",
    "                    print(doc[-1])\n",
    "                    print()\n",
    "                else:\n",
    "                    break\n",
    "                doc = []\n",
    "        else:  # doc에 저장\n",
    "            pieces = vocab.encode_as_pieces(line)\n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "    if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "        print(doc[0])\n",
    "        print(doc[1])\n",
    "        print(doc[-1])\n",
    "        doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/3957761 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac1c512791294204aa9e7b9ad03fe5a9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "doc: 21 instances: 10\n{'tokens': ['[CLS]', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '[MASK]', '[MASK]', '[MASK]', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [10, 11, 12, 13, 14, 15, 41, 42, 43], 'mask_label': ['▁합', '성', '섬', '유', '등', '의', '▁화', '합', '물을']}\n{'tokens': ['[CLS]', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [23, 24, 25, 26, 27, 53, 54, 55, 56], 'mask_label': ['▁유', '기', '화', '학', '에서', '▁화', '합', '물', '은']}\n\ndoc: 14 instances: 7\n{'tokens': ['[CLS]', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '[MASK]', '[MASK]', '[MASK]', '▁화', '합', '물을', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [38, 39, 40, 44, 45, 46, 47, 48, 49], 'mask_label': ['▁탄', '소로', '▁이루어진', '▁연구', '하는', '▁분', '과', '이다', '.']}\n{'tokens': ['[CLS]', '[MASK]', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '[MASK]', '▁화', '합', '물을', '[MASK]', '[MASK]', '▁분', '과', '이다', '.', '[MASK]', '[MASK]', '[MASK]', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '[MASK]', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 40, 44, 45, 50, 51, 52, 61, 62], 'mask_label': ['으로', '▁이루어진', '▁연구', '하는', '▁원래', '▁유', '기', '▁추', '출']}\n\ndoc: 4 instances: 2\n{'tokens': ['[CLS]', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '[MASK]', '[MASK]', '▁분', '과', '이다', '.', '▁원래', '[MASK]', '[MASK]', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [16, 17, 18, 19, 20, 44, 45, 51, 52], 'mask_label': ['▁고', '분', '자', '물', '질', '▁연구', '하는', '▁유', '기']}\n{'tokens': ['[CLS]', '[MASK]', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁고', '분', '자', '물', '질', '[MASK]', '[MASK]', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 10, 11, 12, 13, 14, 15, 21, 22], 'mask_label': ['으로', '▁합', '성', '섬', '유', '등', '의', '▁등', '도']}\n\ndoc: 10 instances: 5\n{'tokens': ['[CLS]', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '許', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '적', '惠', '▁동물', '로부터', '[MASK]', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [40, 53, 54, 55, 56, 57, 58, 61, 62], 'mask_label': ['▁이루어진', '▁화', '합', '물', '은', '▁식물', '이나', '▁추', '출']}\n{'tokens': ['[CLS]', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '[MASK]', '[MASK]', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '[MASK]', '[MASK]', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [23, 24, 25, 26, 27, 38, 39, 51, 52], 'mask_label': ['▁유', '기', '화', '학', '에서', '▁탄', '소로', '▁유', '기']}\n\ndoc: 10 instances: 5\n{'tokens': ['[CLS]', '[MASK]', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁원래', '[MASK]', '[MASK]', '▁화', '합', '물', '은', '[MASK]', '[MASK]', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 46, 47, 48, 49, 51, 52, 57, 58], 'mask_label': ['으로', '▁분', '과', '이다', '.', '▁유', '기', '▁식물', '이나']}\n{'tokens': ['[CLS]', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '[MASK]', '[MASK]', '▁분', '과', '이다', '.', '[MASK]', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '[MASK]', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [44, 45, 50, 53, 54, 55, 56, 61, 62], 'mask_label': ['▁연구', '하는', '▁원래', '▁화', '합', '물', '은', '▁추', '출']}\n\ndoc: 31 instances: 15\n{'tokens': ['[CLS]', '[MASK]', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '[MASK]', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '[MASK]', '[MASK]', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 23, 24, 25, 26, 27, 40, 51, 52], 'mask_label': ['으로', '▁유', '기', '화', '학', '에서', '▁이루어진', '▁유', '기']}\n{'tokens': ['[CLS]', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '[MASK]', '[MASK]', '[MASK]', '▁연구', '하는', '▁분', '과', '이다', '.', '[MASK]', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [23, 24, 25, 26, 27, 41, 42, 43, 50], 'mask_label': ['▁유', '기', '화', '학', '에서', '▁화', '합', '물을', '▁원래']}\n\n"
     ]
    }
   ],
   "source": [
    "# instance 생성 기능 확인\n",
    "count = 5\n",
    "\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = []  # 단락 단위로 문서 저장\n",
    "    for line in tqdm(in_f, total=total):\n",
    "        line = line.strip()\n",
    "        if line == \"\":  # line이 빈줄 일 경우 (새로운 단락을 의미 함)\n",
    "            if 0 < len(doc):\n",
    "                instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "                # save\n",
    "                print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "                print(instances[0])\n",
    "                print(instances[-1])\n",
    "                print()\n",
    "                doc = []\n",
    "                if 0 < count:  # 테스트를 위해서 부분 처리 함\n",
    "                    count -= 1\n",
    "                else:\n",
    "                    break\n",
    "        else:  # doc에 저장\n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "    if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "        instances = create_pretrain_instances(doc, 128)\n",
    "        # save\n",
    "        print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "        print(instances[0])\n",
    "        print(instances[-1])\n",
    "        print()\n",
    "        doc = []"
   ]
  },
  {
   "source": [
    "## Bert Train Dataset Method"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "        for instance in instances:\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "\n",
    "    # 특수문자 7개를 제외한 vocab_list 생성\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):\n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "\n",
    "    # line count 확인\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            doc = []\n",
    "            for line in tqdm(in_f, total=line_cnt):\n",
    "                line = line.strip()\n",
    "                if line == \"\":  # line이 빈줄 일 경우 (새로운 단락을 의미 함)\n",
    "                    if 0 < len(doc):\n",
    "                        save_pretrain_instances(out_f, doc)\n",
    "                        doc = []\n",
    "                else:  # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "            if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "                save_pretrain_instances(out_f, doc)\n",
    "                doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/3957761 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "902a7c77d5df497ea69f41b52528666d"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "pretrain_json_path = os.getenv('HOME')+'/aiffel/bert_pretrain/data/bert_pre_train.json'\n",
    "\n",
    "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "918189"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "# 라인수\n",
    "total = 0\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 0,\n",
       " 0,\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "n_seq = 128\n",
    "# [CLS], tokens_a, [SEP], tokens_b, [SEP]\n",
    "max_seq = n_seq - 3\n",
    "\n",
    "# 만약 일반적인 Numpy Array에다 데이터를 로딩한다면 이렇게 되겠지만\n",
    "# enc_tokens = np.zeros((total, n_seq), np.int32)\n",
    "# dec_tokens = np.zeros((total, n_seq), np.int32)\n",
    "# labels_nsp = np.zeros((total,), np.int32)\n",
    "# labels_mlm = np.zeros((total, n_seq), np.int32)\n",
    "\n",
    "# np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "\n",
    "enc_tokens[0], enc_tokens[-1], segments[0], segments[-1], labels_nsp[0], labels_nsp[-1], labels_mlm[0], labels_mlm[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/918189 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb84cb75fa7a4b2b824084effe12a97e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'tokens': ['[CLS]', '일', '▁~', '[MASK]', '[MASK]', '▁민주', '당', '▁출신', '▁미국', '▁3', '9', '번째', '▁대통령', '▁(19', '7', '7', '년', '[MASK]', '▁1981', '년', ')', '이다', '.', '▁지', '미', '▁카', '터', '는', '[MASK]', '[MASK]', '[MASK]', '▁섬', '터', '▁카운', '티', '▁플', '레', '인', '스', '▁마을', '에서', '▁태어났다', '.', '▁조지', '아', '▁공', '과', '대학교', '를', '▁졸업', '하였다', '.', '▁그', '▁후', '▁해', '군에', '▁들어가', '▁전', '함', '·', '원', '자', '력', '·', '잠', '수', '함', '의', '▁승', '무', '원으로', '▁일', '하였다', '.', '▁195', '3', '년', '▁미국', '▁해군', '▁대', '위로', '▁예', '편', '하였고', '▁이후', '▁땅', '콩', '·', '면', '화', '[MASK]', '▁가', '꿔', '▁많은', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁그의', '▁별', '명이', '▁\"', '땅', '콩', '▁농', '부', '\"', '▁(', 'P', 'e', 'an', 'ut', '▁F', 'ar', 'm', 'er', ')', '로', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '▁지', '미', '▁카', '터', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [3, 4, 9, 10, 11, 17, 28, 29, 30, 90, 94, 95, 96, 97, 98, 119, 120, 121], 'mask_label': ['▁)', '는', '▁3', '9', '번째', '▁~', '▁조지', '아', '주', '▁등을', '▁돈', '을', '▁벌', '었다', '.', '▁알려', '졌다', '.']}\nenc_token: [5, 3629, 203, 6, 6, 1114, 3724, 788, 243, 49, 3632, 796, 663, 1647, 3682, 3682, 3625, 6, 3008, 3625, 3616, 16, 3599, 18, 3686, 207, 3714, 3602, 6, 6, 6, 630, 3714, 3565, 3835, 429, 3740, 3628, 3626, 1369, 10, 1605, 3599, 1755, 3630, 41, 3644, 830, 3624, 1135, 52, 3599, 13, 81, 87, 1501, 2247, 25, 3779, 3873, 3667, 3631, 3813, 3873, 4196, 3636, 3779, 3601, 249, 3725, 1232, 33, 52, 3599, 479, 3652, 3625, 243, 2780, 14, 1509, 168, 3877, 414, 165, 1697, 4290, 3873, 3703, 3683, 6, 21, 5007, 399, 6, 6, 6, 6, 6, 307, 587, 931, 103, 4313, 4290, 613, 3638, 3718, 98, 3878, 3656, 256, 2543, 309, 337, 3735, 181, 3616, 3603, 6, 6, 6, 4, 18, 3686, 207, 3714, 4]\nsegment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\nlabel_nsp: 0\nlabel_mlm: [   0    0    0  241 3602    0    0    0    0   49 3632  796    0    0\n    0    0    0  203    0    0    0    0    0    0    0    0    0    0\n 1755 3630 3646    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0  593    0    0    0 1927 3607  813   17\n 3599    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0  489  376 3599    0    0    0    0\n    0    0]\n\n{'tokens': ['[CLS]', '아', '▁주', '▁상', '원', '▁의원', '▁선거', '에서', '▁낙', '선', '하나', '▁그', '▁선거', '가', '▁부정', '선거', '▁', '였', '음을', '▁입', '증', '하게', '▁되어', '▁당선', '되고', ',', '▁196', '6', '년', '▁조지', '아', '▁주', '▁지', '사', '▁선거', '에', '▁낙', '선', '하지만', '[MASK]', '[MASK]', '▁조지', '아', '▁주', '▁지', '사를', '▁역임', '했다', '.', '▁대통령', '이', '▁되', '기', '▁전', '▁조지', '아', '주', '總', '▁가르', '▁파', '▁두', '번', '▁연', '임', '했으며', ',', '[MASK]', '[MASK]', '▁1975', '년까지', '▁조지', '아', '▁지', '사로', '[MASK]', '[MASK]', '[MASK]', '▁조지', '아', '▁주', '지', '사로', '▁지', '내', '면서', ',', '▁미국', '에', '[MASK]', '▁흑', '인', '▁등', '용', '법을', '▁내', '세', '웠다', '.', '[SEP]', '▁1976', '년', '▁대통령', '▁선거', '에', '▁민주', '당', '▁후보', '로', '▁출', '마', '하여', '▁도', '덕', '주의', '[MASK]', '[MASK]', '▁내', '세', '워', ',', '[MASK]', '[MASK]', '▁누', '르고', '지', '▁달러', '잴', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [39, 40, 57, 58, 59, 66, 67, 74, 75, 76, 88, 114, 115, 120, 121, 124, 125, 126], 'mask_label': ['▁1970', '년', '▁상', '원의', '원을', '▁1971', '년부터', '▁근무', '했다', '.', '▁사는', '▁정책', '으로', '▁포', '드를', '▁당선', '되었다', '.']}\nenc_token: [5, 3630, 37, 76, 3667, 2378, 822, 10, 1567, 3668, 3294, 13, 822, 3608, 2386, 2163, 3596, 3671, 969, 213, 3929, 173, 607, 2387, 317, 3604, 386, 3673, 3625, 1755, 3630, 37, 18, 3620, 822, 3600, 1567, 3668, 1447, 6, 6, 1755, 3630, 37, 18, 451, 1398, 31, 3599, 663, 3597, 450, 3614, 25, 1755, 3630, 3646, 5400, 2190, 146, 157, 3821, 61, 3773, 530, 3604, 6, 6, 3409, 673, 1755, 3630, 18, 982, 6, 6, 6, 1755, 3630, 37, 3610, 982, 18, 3754, 151, 3604, 243, 3600, 6, 1733, 3628, 50, 3717, 2046, 114, 3692, 1853, 3599, 4, 3306, 3625, 663, 822, 3600, 1114, 3724, 958, 3603, 117, 3674, 54, 75, 4089, 238, 6, 6, 114, 3692, 3964, 3604, 6, 6, 807, 2056, 3610, 2178, 7877, 4]\nsegment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nlabel_nsp: 1\nlabel_mlm: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0 1921 3625    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0   76  955  928    0    0    0    0    0    0 3372  523    0    0\n    0    0    0    0 2711   31 3599    0    0    0    0    0    0    0\n    0    0    0    0 3554    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0 1421    9    0    0    0    0  119 1486    0    0 2387   43\n 3599    0]\n\n{'tokens': ['[CLS]', '[MASK]', '▁개발', '을', '▁촉', '구', '했으나', '▁공', '화', '당의', '[MASK]', '[MASK]', '▁무', '산', '되었다', '.', '▁카', '터', '는', '[MASK]', '[MASK]', '[MASK]', '▁이스라엘', '을', '[MASK]', '[MASK]', '[MASK]', '▁캠', '프', '▁데이', '비', '드에서', '▁안', '와', '르', '▁사', '다', '트', '[MASK]', '[MASK]', '▁메', '나', '헴', '▁베', '긴', '▁수상', '과', '▁함께', '▁중', '동', '▁평', '화를', '▁맡았다', '▁캠', '프', '데', '이', '비', '드', '▁협', '정을', '▁체결', '했다', '.', '[SEP]', '▁그러나', '[MASK]', '▁공', '화', '당', '과', '[MASK]', '▁유대', '인', '▁단', '체의', '▁반', '발', '을', '▁일으', '켰', '다', '.', '▁1979', '년', '▁백', '악', '관', '에서', '▁양', '국', '▁간의', '▁평화', '조', '약', '으로', '▁이끌', '어졌다', '.', '▁또한', '▁소련', '과', '▁제', '2', '차', '▁전략', '▁무', '기', '▁제한', '▁협', '상에', '▁조', '인', '했다', '.', '▁카', '터', '는', '▁1970', '년대', '[MASK]', '[MASK]', '▁대한민국', '▁등', '▁인', '권', '▁후', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 10, 11, 19, 20, 21, 24, 25, 26, 38, 39, 52, 66, 71, 100, 101, 120, 121], 'mask_label': ['지', '▁반', '대로', '▁이집', '트', '와', '▁조정', '하여', ',', '▁대통령', '과', '▁위한', '▁이것은', '▁미국의', '▁소련', '과', '▁후반', '▁당시']}\nenc_token: [5, 6, 570, 3607, 2270, 3653, 1003, 41, 3683, 1547, 6, 6, 107, 3726, 43, 3599, 207, 3714, 3602, 6, 6, 6, 3426, 3607, 6, 6, 6, 2432, 3721, 965, 3694, 3552, 172, 3665, 3699, 15, 3598, 3677, 6, 6, 334, 3637, 5887, 271, 4099, 1011, 3644, 280, 35, 3658, 232, 934, 1896, 2432, 3721, 3736, 3597, 3694, 3681, 617, 666, 2525, 31, 3599, 4, 330, 6, 41, 3683, 3724, 3644, 6, 2670, 3628, 164, 1314, 141, 3720, 3607, 1213, 4174, 3598, 3599, 2995, 3625, 456, 3928, 3708, 10, 230, 3643, 2714, 2793, 3676, 3827, 9, 1435, 2521, 3599, 276, 1302, 3644, 30, 3619, 3751, 2835, 107, 3614, 1956, 617, 1824, 53, 3628, 31, 3599, 207, 3714, 3602, 1921, 596, 6, 6, 410, 50, 42, 3830, 81, 4]\nsegment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nlabel_nsp: 1\nlabel_mlm: [   0 3610    0    0    0    0    0    0    0    0  141  448    0    0\n    0    0    0    0    0 2703 3677 3665    0    0 3358   54 3604    0\n    0    0    0    0    0    0    0    0    0    0  663 3644    0    0\n    0    0    0    0    0    0    0    0    0    0  521    0    0    0\n    0    0    0    0    0    0    0    0    0    0 1487    0    0    0\n    0  679    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0 1302 3644    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0 1840  316    0    0    0    0\n    0    0]\n\n{'tokens': ['[CLS]', '[MASK]', '[MASK]', '▁부', '딪', '혀', '吾', '팡', '▁계열', '도에', '▁완', '전', '철', '수', '▁대신', '▁6', ',000', '명을', '▁감', '축', '하는', '▁데', '▁그', '쳤다', '.', '▁또한', '▁박', '정', '희', '[MASK]', '[MASK]', '▁인', '권', '▁문제', '▁등', '과의', '▁논란', '으로', '▁불', '협', '화', '음을', '▁', '냈', '으나', ',', '▁1979', '년', '▁6', '월', '▁하', '순', ',', '▁대한민국', '을', '▁방문', '하여', '▁관계', '가', '▁다', '소', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '▁그러나', '▁주', '[MASK]', '▁미국', '▁대사', '관', '▁인', '질', '▁사건', '에서', '▁인', '질', '▁구', '출', '▁실패', '를', '[MASK]', '▁1980', '년', '[MASK]', '[MASK]', '[MASK]', '▁공', '화', '당의', '▁로', '널', '드', '▁레이', '건', '▁후보', '에게', '▁', '져', '[MASK]', '▁재', '선에', '▁실패', '했다', '.', '▁또한', '▁임', '기', '▁말', '기에', '▁터', '진', '▁소련', '의', '▁아', '프가', '니', '스탄', '▁침공', '▁사건', '으로', '[MASK]', '▁1980', '년', '▁하계', '▁올림픽', '에', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 6, 7, 8, 9, 29, 30, 61, 62, 63, 67, 81, 84, 85, 86, 99, 121], 'mask_label': ['▁반', '대에', '▁주', '한', '미', '군은', '▁정', '권의', '▁회복', '되었다', '.', '▁이란', '▁이유로', '▁대통령', '▁선거', '에서', '▁결국', '▁인해']}\nenc_token: [5, 6, 6, 51, 5148, 4178, 6398, 4758, 2440, 1464, 443, 3640, 3917, 3636, 1083, 125, 847, 859, 209, 3909, 38, 189, 13, 1523, 3599, 276, 338, 3642, 4055, 6, 6, 42, 3830, 550, 50, 786, 2408, 9, 128, 3993, 3683, 969, 3596, 4121, 191, 3604, 2995, 3625, 125, 3662, 27, 3946, 3604, 410, 3607, 2017, 54, 704, 3608, 29, 3688, 6, 6, 6, 4, 330, 37, 6, 243, 2630, 3708, 42, 3892, 636, 10, 42, 3892, 73, 3771, 1579, 3624, 6, 1640, 3625, 6, 6, 6, 41, 3683, 1547, 194, 4044, 3681, 1169, 3803, 958, 113, 3596, 3944, 6, 174, 2087, 1579, 31, 3599, 276, 273, 3614, 150, 329, 870, 3713, 1302, 3601, 26, 2986, 3733, 1323, 3232, 636, 9, 6, 1640, 3625, 2219, 779, 3600, 4]\nsegment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nlabel_nsp: 0\nlabel_mlm: [   0  141  867    0    0    0   37 3612 3686  941    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0   36 2649    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0 3332   43 3599    0    0    0 3290    0    0\n    0    0    0    0    0    0    0    0    0    0    0 1827    0    0\n  663  822   10    0    0    0    0    0    0    0    0    0    0    0\n    0  875    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0  751    0    0    0    0\n    0    0]\n\n{'tokens': ['[CLS]', '한', '▁뒤', '▁민주', '주의', '▁실', '현', '을', '▁위해', '▁제', '▁3', '세', '계의', '[MASK]', '▁감', '시', '▁활동', '▁및', '▁기', '니', '[MASK]', '[MASK]', '[MASK]', '▁의한', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁질', '병', '▁방', '재', '를', '▁위해', '▁힘', '썼', '다', '.', '▁미국의', '▁빈', '곤', '층', '▁지원', '▁활동', ',', '▁사랑', '의', '[MASK]', '[MASK]', '[MASK]', '▁운동', ',', '▁국제', '▁분', '쟁', '▁중', '재', '▁등의', '[MASK]', '[MASK]', '▁했다', '.', '[SEP]', '[MASK]', '[MASK]', '▁~', '▁1980', '년', '▁대한민국의', '▁정치적', '▁격', '변', '기', '[MASK]', '▁대통령', '이었던', '▁그는', '▁이에', '▁대해', '▁애', '매', '한', '▁태', '도를', '▁보', '였고', ',', '▁이는', '▁후에', '▁대한민국', '▁내에서', '▁고', '조', '되는', '▁반', '미', '▁운동', '의', '▁한', '▁원', '인이', '▁', '됐다', '.', '▁10', '월', '▁26', '일', ',', '▁박', '정', '희', '▁대통령', '이', '▁김', '재', '규', '▁중앙', '정보', '부', '장에', '▁의해', '▁살해', '된', '▁것에', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [13, 20, 21, 22, 24, 25, 26, 27, 28, 29, 49, 50, 51, 60, 61, 65, 66, 75], 'mask_label': ['▁선거', '▁벌', '레', '에', '▁드', '라', '쿤', '쿠', '르', '스', '▁집', '짓', '기', '▁활동', '도', '▁1979', '년', '▁당시의']}\nenc_token: [5, 3612, 339, 1114, 238, 158, 3756, 3607, 231, 30, 49, 3692, 1654, 6, 209, 3623, 375, 228, 24, 3733, 6, 6, 6, 1332, 6, 6, 6, 6, 6, 6, 761, 3886, 95, 3729, 3624, 231, 947, 4437, 3598, 3599, 679, 1412, 4234, 4083, 770, 375, 3604, 1424, 3601, 6, 6, 6, 887, 3604, 605, 147, 3972, 35, 3729, 507, 6, 6, 345, 3599, 4, 6, 6, 203, 1640, 3625, 447, 2843, 1032, 3889, 3614, 6, 663, 1277, 202, 695, 433, 442, 3823, 3612, 227, 701, 47, 2470, 3604, 594, 1140, 410, 3428, 70, 3676, 267, 141, 3686, 887, 3601, 34, 129, 828, 3596, 1027, 3599, 131, 3662, 981, 3629, 3604, 338, 3642, 4055, 663, 3597, 200, 3729, 3958, 782, 2275, 3638, 1312, 355, 2591, 3711, 2057, 4]\nsegment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nlabel_nsp: 0\nlabel_mlm: [   0    0    0    0    0    0    0    0    0    0    0    0    0  822\n    0    0    0    0    0    0  813 3740 3600    0  311 3635 4956 3937\n 3699 3626    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0  313 4333 3614    0    0    0    0\n    0    0    0    0  375 3627    0    0    0 2995 3625    0    0    0\n    0    0    0    0    0 3195    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0]\n\n{'tokens': ['[CLS]', '▁미국', '이', '▁북', '핵', '▁위', '기', ',', '▁코', '소', '보', '▁전쟁', ',', '▁이', '라크', '▁전쟁', '과', '▁같이', '▁미국', '이', '▁군사', '적', '▁행', '동을', '[MASK]', '[MASK]', '[MASK]', '▁선택', '하는', '[MASK]', '[MASK]', '▁사고', '를', '▁버', '리고', '▁군사', '적', '▁행', '동을', '[MASK]', '[MASK]', '[MASK]', '▁행', '위에', '[MASK]', '▁깊', '은', '▁유', '감을', '▁표시', '▁하며', '▁미국의', '▁군사', '적', '[MASK]', '[MASK]', '▁강한', '▁반대', '[MASK]', '[MASK]', '▁보', '이고', '▁있다', '.', '[SEP]', '▁특히', '▁국제', '▁분', '쟁', '▁조', '정을', '▁위해', '▁북한', '의', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁아이', '티', '의', '▁세', '드', '라스', '▁장', '군', ',', '▁팔', '레', '인', '스타', '인의', '▁하', '마', '스', ',', '▁보', '스', '니아', '의', '▁세르', '비아', '계', '▁정', '권', '▁같이', '[MASK]', '▁정부', '에', '▁대해', '▁협', '상을', '▁거부', '하면서', '▁사', '태', '의', '▁위', '기를', '▁초', '래', '한', '▁인물', '▁및', '▁단', '체를', '▁직접', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [24, 25, 26, 29, 30, 39, 40, 41, 44, 54, 55, 58, 59, 74, 75, 76, 77, 106], 'mask_label': ['▁최', '후', '로', '▁전통', '적', '▁선', '행', '하는', '▁대해', '▁활동', '에', '▁입', '장을', '▁김', '일', '성', ',', '▁미국']}\nenc_token: [5, 243, 3597, 251, 4166, 45, 3614, 3604, 258, 3688, 3672, 506, 3604, 8, 3553, 506, 3644, 733, 243, 3597, 1250, 3657, 236, 1629, 6, 6, 6, 1715, 38, 6, 6, 1646, 3624, 407, 999, 1250, 3657, 236, 1629, 6, 6, 6, 236, 1157, 6, 1910, 3613, 46, 2196, 2466, 1368, 679, 1250, 3657, 6, 6, 2632, 1216, 6, 6, 47, 458, 28, 3599, 4, 698, 605, 147, 3972, 53, 666, 231, 1876, 3601, 6, 6, 6, 6, 520, 3835, 3601, 74, 3681, 1951, 104, 3722, 3604, 961, 3740, 3628, 936, 692, 27, 3674, 3626, 3604, 47, 3626, 491, 3601, 3189, 852, 3704, 36, 3830, 733, 6, 513, 3600, 433, 617, 460, 2324, 421, 15, 3800, 3601, 45, 333, 192, 3808, 3612, 1178, 228, 164, 1396, 1069, 4]\nsegment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nlabel_nsp: 1\nlabel_mlm: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0  130 3706 3603    0\n    0 1306 3657    0    0    0    0    0    0    0    0   57 3752   38\n    0    0  433    0    0    0    0    0    0    0    0    0  375 3600\n    0    0  213  480    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0  200 3629 3650 3604    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0  243    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0]\n\n"
     ]
    }
   ],
   "source": [
    "# 라인 단위로 처리\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for i, line in enumerate(tqdm(f, total=total)):\n",
    "        if 5 < i:  # 테스트를 위해서 5개만 확인\n",
    "            break\n",
    "        data = json.loads(line)\n",
    "        # encoder token\n",
    "        enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "        enc_token += [0] * (n_seq - len(enc_token))\n",
    "        # segment\n",
    "        segment = data[\"segment\"]\n",
    "        segment += [0] * (n_seq - len(segment))\n",
    "        # nsp label\n",
    "        label_nsp = data[\"is_next\"]\n",
    "        # mlm label\n",
    "        mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "        mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "        label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "        label_mlm[mask_idx] = mask_label\n",
    "\n",
    "        print(data)\n",
    "        print(\"enc_token:\", enc_token)\n",
    "        print(\"segment:\", segment)\n",
    "        print(\"label_nsp:\", label_nsp)\n",
    "        print(\"label_mlm:\", label_mlm)\n",
    "        print()\n",
    "\n",
    "        assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "        enc_tokens[i] = enc_token\n",
    "        segments[i] = segment\n",
    "        labels_nsp[i] = label_nsp\n",
    "        labels_mlm[i] = label_mlm"
   ]
  },
  {
   "source": [
    "## load pretrained data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    학습에 필요한 데이터를 로드\n",
    "    :param vocab: vocab\n",
    "    :param filename: 전처리된 json 파일\n",
    "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
    "    :param count: 데이터 수 제한 (None이면 전체)\n",
    "    :return enc_tokens: encoder inputs\n",
    "    :return segments: segment inputs\n",
    "    :return labels_nsp: nsp labels\n",
    "    :return labels_mlm: mlm labels\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            # 데이터 수 제한\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "    \n",
    "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            # encoder token\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "            # segment\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "            # nsp label\n",
    "            label_nsp = data[\"is_next\"]\n",
    "            # mlm label\n",
    "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i] = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/128000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbae9cc4db6443528ef387c5162aef51"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data load early stop 128000 128000\n"
     ]
    }
   ],
   "source": [
    "# 128000건만 메모리에 로딩\n",
    "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=128000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(memmap([   5, 3629,  203,    6,    6, 1114, 3724,  788,  243,   49, 3632,\n",
       "          796,  663, 1647, 3682, 3682, 3625,    6, 3008, 3625, 3616,   16,\n",
       "         3599,   18, 3686,  207, 3714, 3602,    6,    6,    6,  630, 3714,\n",
       "         3565, 3835,  429, 3740, 3628, 3626, 1369,   10, 1605, 3599, 1755,\n",
       "         3630,   41, 3644,  830, 3624, 1135,   52, 3599,   13,   81,   87,\n",
       "         1501, 2247,   25, 3779, 3873, 3667, 3631, 3813, 3873, 4196, 3636,\n",
       "         3779, 3601,  249, 3725, 1232,   33,   52, 3599,  479, 3652, 3625,\n",
       "          243, 2780,   14, 1509,  168, 3877,  414,  165, 1697, 4290, 3873,\n",
       "         3703, 3683,    6,   21, 5007,  399,    6,    6,    6,    6,    6,\n",
       "          307,  587,  931,  103, 4313, 4290,  613, 3638, 3718,   98, 3878,\n",
       "         3656,  256, 2543,  309,  337, 3735,  181, 3616, 3603,    6,    6,\n",
       "            6,    4,   18, 3686,  207, 3714,    4], dtype=int32),\n",
       " memmap([   5, 3676,  848, 3784, 1931,   58, 3676,  416, 2316, 3619, 3625,\n",
       "         3617, 3744, 4335,   12, 3625, 3616,  175, 3662,    7, 3629,  203,\n",
       "            6,    6,    6,    6,    6,    6,  143, 3625, 3616,  131, 3662,\n",
       "          342, 3629, 3616, 3602,  176,  334,  829, 1115, 3665,    6,    6,\n",
       "         3451, 1633,  375,  671, 1644, 3608,  547, 3423,  765,  815, 3604,\n",
       "            6,    6,    6, 2375, 3608, 3604,  532, 2589, 3599,    4,  307,\n",
       "          323,    6,  321, 3611,  622,  122, 3725, 3620, 3627, 3837, 3608,\n",
       "            6,  176,  268, 4082,   94,  567, 4014, 3617, 7474, 3616, 3830,\n",
       "           66, 3590,  307,  192, 1272,  158, 3788,  353, 3599,  202,  316,\n",
       "         3600,  176,   10,  323,  476, 3663, 1329,  605,  238, 3631, 2470,\n",
       "         3604, 1939,  106, 3627,   13,    6,    6, 1128,   48,    6,    6,\n",
       "          848, 3784, 3833,    8, 3637, 2263,    4], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 0,\n",
       " 1,\n",
       " memmap([   0,    0,    0,  241, 3602,    0,    0,    0,    0,   49, 3632,\n",
       "          796,    0,    0,    0,    0,    0,  203,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0, 1755, 3630, 3646,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,  593,    0,    0,    0, 1927, 3607,  813,   17, 3599,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,  489,  376,\n",
       "         3599,    0,    0,    0,    0,    0,    0], dtype=int32),\n",
       " memmap([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          578, 3652, 3625, 3617, 4148, 3665,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0, 1381, 4148,\n",
       "         3451,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          752, 3608, 3604,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0, 2143,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          347,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,  162,  490,    0,    0,   28, 3599,\n",
       "            0,    0,    0,    0,    0,    0,    0], dtype=int32))"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "# 처음과 마지막 확인\n",
    "pre_train_inputs[0][0], pre_train_inputs[0][-1], pre_train_inputs[1][0], pre_train_inputs[1][-1], pre_train_labels[0][0], pre_train_labels[0][-1], pre_train_labels[1][0], pre_train_labels[1][-1]"
   ]
  },
  {
   "source": [
    "## 모델 구현"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1 + K.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성 함\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shaed Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Positional Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: positional embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
    "        # transpose and liner\n",
    "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "\n",
    "        return attn_out\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionalEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: (enc_tokens, segments)\n",
    "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
    "        \"\"\"\n",
    "        enc_tokens, segments = inputs\n",
    "\n",
    "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# Encoder Layer class 정의\n",
    "class PooledOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    " \n",
    "    def call(self, inputs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def build_model_pre_train(config):\n",
    "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
    "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
    "\n",
    "    bert = BERT(config)\n",
    "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
    "\n",
    "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
    "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
    "\n",
    "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
    "    return model\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 256,\n",
       " 'n_vocab': 8007,\n",
       " 'i_pad': 0}"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7747 - nsp_loss: 0.7198 - mlm_loss: 9.0549 - nsp_acc: 0.6000 - mlm_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5973 - nsp_loss: 0.6165 - mlm_loss: 7.9808 - nsp_acc: 0.8000 - mlm_acc: 0.0000e+00\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f563c278650>"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "n_seq = 10\n",
    "\n",
    "# make test inputs\n",
    "enc_tokens = np.random.randint(0, len(vocab), (10, n_seq))\n",
    "segments = np.random.randint(0, 2, (10, n_seq))\n",
    "labels_nsp = np.random.randint(0, 2, (10,))\n",
    "labels_mlm = np.random.randint(0, len(vocab), (10, n_seq))\n",
    "\n",
    "test_model = build_model_pre_train(config)\n",
    "test_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=[\"acc\"])\n",
    "\n",
    "# test model fit\n",
    "test_model.fit((enc_tokens, segments), (labels_nsp, labels_mlm), epochs=2, batch_size=5)"
   ]
  },
  {
   "source": [
    "## pretrain 진행"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    loss 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # loss 계산\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    acc 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # 정답 여부 확인\n",
    "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
    "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
    "    matches *= mask\n",
    "    # 정확도 계산\n",
    "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
    "    return accuracy\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    CosineSchedule Class\n",
    "    \"\"\"\n",
    "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param train_steps: 학습 step 총 합\n",
    "        :param warmup_steps: warmup steps\n",
    "        :param max_lr: 최대 learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0 < warmup_steps < train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.train_steps = train_steps\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        \"\"\"\n",
    "        learning rate 계산\n",
    "        :param step_num: 현재 step number\n",
    "        :retrun: 계산된 learning rate\n",
    "        \"\"\"\n",
    "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
    "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
    "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
    "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
    "        return (state * lr1 + (1 - state) * lr2) * self.max_lr\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 397.553125 262.19625\" width=\"397.553125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-05-14T17:22:02.488497</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 397.553125 262.19625 \nL 397.553125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 55.553125 224.64 \nL 390.353125 224.64 \nL 390.353125 7.2 \nL 55.553125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m39d65b8cd5\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"70.771307\" xlink:href=\"#m39d65b8cd5\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(67.590057 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.826275\" xlink:href=\"#m39d65b8cd5\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 500 -->\n      <g transform=\"translate(99.282525 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"146.881243\" xlink:href=\"#m39d65b8cd5\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1000 -->\n      <g transform=\"translate(134.156243 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"184.936212\" xlink:href=\"#m39d65b8cd5\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 1500 -->\n      <g transform=\"translate(172.211212 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"222.99118\" xlink:href=\"#m39d65b8cd5\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2000 -->\n      <g transform=\"translate(210.26618 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"261.046148\" xlink:href=\"#m39d65b8cd5\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2500 -->\n      <g transform=\"translate(248.321148 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"299.101117\" xlink:href=\"#m39d65b8cd5\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 3000 -->\n      <g transform=\"translate(286.376117 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"337.156085\" xlink:href=\"#m39d65b8cd5\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 3500 -->\n      <g transform=\"translate(324.431085 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"375.211053\" xlink:href=\"#m39d65b8cd5\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 4000 -->\n      <g transform=\"translate(362.486053 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Step -->\n     <g transform=\"translate(211.567969 252.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"102.685547\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"164.208984\" xlink:href=\"#DejaVuSans-112\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m60daf4b6e7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.553125\" xlink:href=\"#m60daf4b6e7\" y=\"214.756364\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.00000 -->\n      <g transform=\"translate(7.2 218.555582)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.553125\" xlink:href=\"#m60daf4b6e7\" y=\"175.22182\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.00005 -->\n      <g transform=\"translate(7.2 179.021039)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.553125\" xlink:href=\"#m60daf4b6e7\" y=\"135.687276\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.00010 -->\n      <g transform=\"translate(7.2 139.486495)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.553125\" xlink:href=\"#m60daf4b6e7\" y=\"96.152733\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.00015 -->\n      <g transform=\"translate(7.2 99.951952)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.553125\" xlink:href=\"#m60daf4b6e7\" y=\"56.618189\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.00020 -->\n      <g transform=\"translate(7.2 60.417408)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.553125\" xlink:href=\"#m60daf4b6e7\" y=\"17.083646\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.00025 -->\n      <g transform=\"translate(7.2 20.882865)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"349.902344\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pc3c64cb0ab)\" d=\"M 70.771307 214.756364 \nL 108.902385 17.083682 \nL 112.936212 17.19971 \nL 116.970038 17.539139 \nL 121.003865 18.101164 \nL 125.037692 18.88452 \nL 129.147628 19.908468 \nL 133.333675 21.183179 \nL 137.595831 22.718249 \nL 141.934098 24.522458 \nL 146.348474 26.603825 \nL 150.83896 28.969369 \nL 155.405556 31.62498 \nL 160.124372 34.62582 \nL 164.995408 37.987352 \nL 170.094774 41.781742 \nL 175.34636 45.969444 \nL 180.826275 50.624913 \nL 186.61063 55.834377 \nL 192.775535 61.693657 \nL 199.3971 68.305227 \nL 206.475324 75.692617 \nL 214.390757 84.283138 \nL 223.600059 94.619337 \nL 235.701539 108.563447 \nL 263.025007 140.155728 \nL 272.310419 150.48244 \nL 280.225852 158.963274 \nL 287.380186 166.308143 \nL 293.925641 172.715138 \nL 300.090546 178.440945 \nL 305.874901 183.513446 \nL 311.354816 188.02931 \nL 316.606402 192.074727 \nL 321.705768 195.723566 \nL 326.576804 198.939768 \nL 331.29562 201.794351 \nL 335.938326 204.343456 \nL 340.428812 206.556921 \nL 344.843188 208.485187 \nL 349.181455 210.135863 \nL 353.443611 211.51748 \nL 357.629658 212.639383 \nL 361.739594 213.511608 \nL 365.773421 214.144796 \nL 369.807248 214.555724 \nL 373.841074 214.743462 \nL 375.134943 214.756322 \nL 375.134943 214.756322 \n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 55.553125 224.64 \nL 55.553125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 390.353125 224.64 \nL 390.353125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 55.553125 224.64 \nL 390.353125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 55.553125 7.2 \nL 390.353125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc3c64cb0ab\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"55.553125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# compute lr \n",
    "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
    "lrs = []\n",
    "for step_num in range(4000):\n",
    "    lrs.append(test_schedule(float(step_num)).numpy())\n",
    "\n",
    "# draw\n",
    "plt.plot(lrs, 'r-', label='learning_rate')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nenc_tokens (InputLayer)         [(None, None)]       0                                            \n__________________________________________________________________________________________________\nsegments (InputLayer)           [(None, None)]       0                                            \n__________________________________________________________________________________________________\nbert (BERT)                     ((None, 256), (None, 4485632     enc_tokens[0][0]                 \n                                                                 segments[0][0]                   \n__________________________________________________________________________________________________\npooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n__________________________________________________________________________________________________\nnsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n__________________________________________________________________________________________________\nmlm (Softmax)                   (None, None, 8007)   0           bert[0][1]                       \n==================================================================================================\nTotal params: 4,551,936\nTrainable params: 4,551,936\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "pre_train_model = build_model_pre_train(config)\n",
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_steps: 20000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# compile\n",
    "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 19.5797 - nsp_loss: 0.6502 - mlm_loss: 18.9295 - nsp_acc: 0.5888 - mlm_lm_acc: 0.1086\n",
      "Epoch 00001: mlm_lm_acc improved from -inf to 0.10859, saving model to /home/aiffel-dj53/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "2000/2000 [==============================] - 237s 119ms/step - loss: 19.5797 - nsp_loss: 0.6502 - mlm_loss: 18.9295 - nsp_acc: 0.5888 - mlm_lm_acc: 0.1086\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 17.5016 - nsp_loss: 0.6226 - mlm_loss: 16.8791 - nsp_acc: 0.6191 - mlm_lm_acc: 0.1301\n",
      "Epoch 00002: mlm_lm_acc improved from 0.10859 to 0.13009, saving model to /home/aiffel-dj53/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "2000/2000 [==============================] - 255s 128ms/step - loss: 17.5016 - nsp_loss: 0.6226 - mlm_loss: 16.8791 - nsp_acc: 0.6191 - mlm_lm_acc: 0.1301\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 15.9204 - nsp_loss: 0.6160 - mlm_loss: 15.3044 - nsp_acc: 0.6268 - mlm_lm_acc: 0.1503\n",
      "Epoch 00003: mlm_lm_acc improved from 0.13009 to 0.15033, saving model to /home/aiffel-dj53/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 15.9204 - nsp_loss: 0.6160 - mlm_loss: 15.3044 - nsp_acc: 0.6268 - mlm_lm_acc: 0.1503\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 14.1131 - nsp_loss: 0.6122 - mlm_loss: 13.5009 - nsp_acc: 0.6276 - mlm_lm_acc: 0.1900\n",
      "Epoch 00004: mlm_lm_acc improved from 0.15033 to 0.19001, saving model to /home/aiffel-dj53/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "2000/2000 [==============================] - 251s 126ms/step - loss: 14.1131 - nsp_loss: 0.6122 - mlm_loss: 13.5009 - nsp_acc: 0.6276 - mlm_lm_acc: 0.1900\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 13.3575 - nsp_loss: 0.6073 - mlm_loss: 12.7502 - nsp_acc: 0.6380 - mlm_lm_acc: 0.2129\n",
      "Epoch 00005: mlm_lm_acc improved from 0.19001 to 0.21288, saving model to /home/aiffel-dj53/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "2000/2000 [==============================] - 245s 123ms/step - loss: 13.3575 - nsp_loss: 0.6073 - mlm_loss: 12.7502 - nsp_acc: 0.6380 - mlm_lm_acc: 0.2129\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 12.9158 - nsp_loss: 0.6027 - mlm_loss: 12.3131 - nsp_acc: 0.6462 - mlm_lm_acc: 0.2272\n",
      "Epoch 00006: mlm_lm_acc improved from 0.21288 to 0.22718, saving model to /home/aiffel-dj53/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "2000/2000 [==============================] - 244s 122ms/step - loss: 12.9158 - nsp_loss: 0.6027 - mlm_loss: 12.3131 - nsp_acc: 0.6462 - mlm_lm_acc: 0.2272\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 12.6104 - nsp_loss: 0.5965 - mlm_loss: 12.0139 - nsp_acc: 0.6585 - mlm_lm_acc: 0.2377\n",
      "Epoch 00007: mlm_lm_acc improved from 0.22718 to 0.23770, saving model to /home/aiffel-dj53/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "2000/2000 [==============================] - 227s 114ms/step - loss: 12.6104 - nsp_loss: 0.5965 - mlm_loss: 12.0139 - nsp_acc: 0.6585 - mlm_lm_acc: 0.2377\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 12.4066 - nsp_loss: 0.5909 - mlm_loss: 11.8157 - nsp_acc: 0.6692 - mlm_lm_acc: 0.2446\n",
      "Epoch 00008: mlm_lm_acc improved from 0.23770 to 0.24455, saving model to /home/aiffel-dj53/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "2000/2000 [==============================] - 227s 114ms/step - loss: 12.4066 - nsp_loss: 0.5909 - mlm_loss: 11.8157 - nsp_acc: 0.6692 - mlm_lm_acc: 0.2446\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 12.2805 - nsp_loss: 0.5866 - mlm_loss: 11.6938 - nsp_acc: 0.6772 - mlm_lm_acc: 0.2487\n",
      "Epoch 00009: mlm_lm_acc improved from 0.24455 to 0.24871, saving model to /home/aiffel-dj53/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "2000/2000 [==============================] - 246s 123ms/step - loss: 12.2805 - nsp_loss: 0.5866 - mlm_loss: 11.6938 - nsp_acc: 0.6772 - mlm_lm_acc: 0.2487\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 12.2228 - nsp_loss: 0.5842 - mlm_loss: 11.6386 - nsp_acc: 0.6823 - mlm_lm_acc: 0.2505\n",
      "Epoch 00010: mlm_lm_acc improved from 0.24871 to 0.25046, saving model to /home/aiffel-dj53/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "2000/2000 [==============================] - 263s 132ms/step - loss: 12.2228 - nsp_loss: 0.5842 - mlm_loss: 11.6386 - nsp_acc: 0.6823 - mlm_lm_acc: 0.2505\n"
     ]
    }
   ],
   "source": [
    "# save weights callback\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
    "# train\n",
    "history = pre_train_model.fit(pre_train_inputs, pre_train_labels, epochs=epochs, batch_size=batch_size, callbacks=[save_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 864x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.203196pt\" version=\"1.1\" viewBox=\"0 0 713.265625 262.203196\" width=\"713.265625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-05-14T18:02:57.859524</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.203196 \nL 713.265625 262.203196 \nL 713.265625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 224.646946 \nL 340.829261 224.646946 \nL 340.829261 7.206946 \nL 36.465625 7.206946 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m80c97dab78\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.300336\" xlink:href=\"#m80c97dab78\" y=\"224.646946\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(47.119086 239.245383)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"111.787939\" xlink:href=\"#m80c97dab78\" y=\"224.646946\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(108.606689 239.245383)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"173.275542\" xlink:href=\"#m80c97dab78\" y=\"224.646946\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(170.094292 239.245383)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.763146\" xlink:href=\"#m80c97dab78\" y=\"224.646946\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(231.581896 239.245383)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"296.250749\" xlink:href=\"#m80c97dab78\" y=\"224.646946\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(293.069499 239.245383)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- Epoch -->\n     <g transform=\"translate(173.336506 252.923508)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m0696afe9ac\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m0696afe9ac\" y=\"221.058207\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <g transform=\"translate(13.5625 224.857426)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m0696afe9ac\" y=\"194.120377\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 2.5 -->\n      <g transform=\"translate(13.5625 197.919596)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m0696afe9ac\" y=\"167.182546\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5.0 -->\n      <g transform=\"translate(13.5625 170.981765)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m0696afe9ac\" y=\"140.244716\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 7.5 -->\n      <g transform=\"translate(13.5625 144.043934)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m0696afe9ac\" y=\"113.306885\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 10.0 -->\n      <g transform=\"translate(7.2 117.106104)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m0696afe9ac\" y=\"86.369054\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 12.5 -->\n      <g transform=\"translate(7.2 90.168273)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m0696afe9ac\" y=\"59.431224\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 15.0 -->\n      <g transform=\"translate(7.2 63.230443)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m0696afe9ac\" y=\"32.493393\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 17.5 -->\n      <g transform=\"translate(7.2 36.292612)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p8d21ae43cf)\" d=\"M 50.300336 214.051713 \nL 81.044137 214.349549 \nL 111.787939 214.420572 \nL 142.531741 214.461481 \nL 173.275542 214.514699 \nL 204.019344 214.563906 \nL 234.763146 214.63101 \nL 265.506947 214.690793 \nL 296.250749 214.737053 \nL 326.994551 214.763309 \n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p8d21ae43cf)\" d=\"M 50.300336 17.090582 \nL 81.044137 39.184199 \nL 111.787939 56.151094 \nL 142.531741 75.583955 \nL 173.275542 83.673185 \nL 204.019344 88.382815 \nL 234.763146 91.607136 \nL 265.506947 93.742646 \nL 296.250749 95.055699 \nL 326.994551 95.650482 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 224.646946 \nL 36.465625 7.206946 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 340.829261 224.646946 \nL 340.829261 7.206946 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 224.646946 \nL 340.829261 224.646946 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 7.206946 \nL 340.829261 7.206946 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 255.254261 45.119446 \nL 333.829261 45.119446 \nQ 335.829261 45.119446 335.829261 43.119446 \nL 335.829261 14.206946 \nQ 335.829261 12.206946 333.829261 12.206946 \nL 255.254261 12.206946 \nQ 253.254261 12.206946 253.254261 14.206946 \nL 253.254261 43.119446 \nQ 253.254261 45.119446 255.254261 45.119446 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 257.254261 20.305383 \nL 277.254261 20.305383 \n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_17\"/>\n    <g id=\"text_15\">\n     <!-- nsp_loss -->\n     <g transform=\"translate(285.254261 23.805383)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n       <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"63.378906\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"115.478516\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"178.955078\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"228.955078\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"256.738281\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"317.919922\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"370.019531\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 257.254261 35.261633 \nL 277.254261 35.261633 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_19\"/>\n    <g id=\"text_16\">\n     <!-- mlm_loss -->\n     <g transform=\"translate(285.254261 38.761633)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"97.412109\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"125.195312\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"222.607422\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"272.607422\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"300.390625\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"361.572266\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"413.671875\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 401.701989 224.646946 \nL 706.065625 224.646946 \nL 706.065625 7.206946 \nL 401.701989 7.206946 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_6\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"415.536699\" xlink:href=\"#m80c97dab78\" y=\"224.646946\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 0 -->\n      <g transform=\"translate(412.355449 239.245383)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"477.024303\" xlink:href=\"#m80c97dab78\" y=\"224.646946\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 2 -->\n      <g transform=\"translate(473.843053 239.245383)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"538.511906\" xlink:href=\"#m80c97dab78\" y=\"224.646946\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 4 -->\n      <g transform=\"translate(535.330656 239.245383)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_23\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"599.999509\" xlink:href=\"#m80c97dab78\" y=\"224.646946\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 6 -->\n      <g transform=\"translate(596.818259 239.245383)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"661.487113\" xlink:href=\"#m80c97dab78\" y=\"224.646946\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 8 -->\n      <g transform=\"translate(658.305863 239.245383)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_22\">\n     <!-- Epoch -->\n     <g transform=\"translate(538.572869 252.923508)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_9\">\n     <g id=\"line2d_25\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"401.701989\" xlink:href=\"#m0696afe9ac\" y=\"217.723166\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 0.1 -->\n      <g transform=\"translate(378.798864 221.522385)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"401.701989\" xlink:href=\"#m0696afe9ac\" y=\"183.269175\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 0.2 -->\n      <g transform=\"translate(378.798864 187.068394)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_27\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"401.701989\" xlink:href=\"#m0696afe9ac\" y=\"148.815184\"/>\n      </g>\n     </g>\n     <g id=\"text_25\">\n      <!-- 0.3 -->\n      <g transform=\"translate(378.798864 152.614403)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"401.701989\" xlink:href=\"#m0696afe9ac\" y=\"114.361193\"/>\n      </g>\n     </g>\n     <g id=\"text_26\">\n      <!-- 0.4 -->\n      <g transform=\"translate(378.798864 118.160411)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_29\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"401.701989\" xlink:href=\"#m0696afe9ac\" y=\"79.907201\"/>\n      </g>\n     </g>\n     <g id=\"text_27\">\n      <!-- 0.5 -->\n      <g transform=\"translate(378.798864 83.70642)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"line2d_30\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"401.701989\" xlink:href=\"#m0696afe9ac\" y=\"45.45321\"/>\n      </g>\n     </g>\n     <g id=\"text_28\">\n      <!-- 0.6 -->\n      <g transform=\"translate(378.798864 49.252429)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_15\">\n     <g id=\"line2d_31\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"401.701989\" xlink:href=\"#m0696afe9ac\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_29\">\n      <!-- 0.7 -->\n      <g transform=\"translate(378.798864 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_32\">\n    <path clip-path=\"url(#p9c37792a90)\" d=\"M 415.536699 49.310451 \nL 446.280501 38.874642 \nL 477.024303 36.226009 \nL 507.768104 35.937989 \nL 538.511906 32.37145 \nL 569.255708 29.537088 \nL 599.999509 25.30031 \nL 630.743311 21.61805 \nL 661.487113 18.864415 \nL 692.230914 17.090582 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path clip-path=\"url(#p9c37792a90)\" d=\"M 415.536699 214.763309 \nL 446.280501 207.357055 \nL 477.024303 200.384118 \nL 507.768104 186.712193 \nL 538.511906 178.833067 \nL 569.255708 173.904389 \nL 599.999509 170.28135 \nL 630.743311 167.918627 \nL 661.487113 166.487311 \nL 692.230914 165.884544 \n\" style=\"fill:none;stroke:#000000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 401.701989 224.646946 \nL 401.701989 7.206946 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 706.065625 224.646946 \nL 706.065625 7.206946 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 401.701989 224.646946 \nL 706.065625 224.646946 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 401.701989 7.206946 \nL 706.065625 7.206946 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_13\">\n     <path d=\"M 622.68125 219.646946 \nL 699.065625 219.646946 \nQ 701.065625 219.646946 701.065625 217.646946 \nL 701.065625 188.734446 \nQ 701.065625 186.734446 699.065625 186.734446 \nL 622.68125 186.734446 \nQ 620.68125 186.734446 620.68125 188.734446 \nL 620.68125 217.646946 \nQ 620.68125 219.646946 622.68125 219.646946 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_34\">\n     <path d=\"M 624.68125 194.832883 \nL 644.68125 194.832883 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_35\"/>\n    <g id=\"text_30\">\n     <!-- nsp_acc -->\n     <g transform=\"translate(652.68125 198.332883)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"63.378906\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"115.478516\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"178.955078\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"228.955078\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"290.234375\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"345.214844\" xlink:href=\"#DejaVuSans-99\"/>\n     </g>\n    </g>\n    <g id=\"line2d_36\">\n     <path d=\"M 624.68125 209.789133 \nL 644.68125 209.789133 \n\" style=\"fill:none;stroke:#000000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_37\"/>\n    <g id=\"text_31\">\n     <!-- mlm_acc -->\n     <g transform=\"translate(652.68125 213.289133)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"97.412109\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"125.195312\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"222.607422\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"272.607422\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"333.886719\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"388.867188\" xlink:href=\"#DejaVuSans-99\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p8d21ae43cf\">\n   <rect height=\"217.44\" width=\"304.363636\" x=\"36.465625\" y=\"7.206946\"/>\n  </clipPath>\n  <clipPath id=\"p9c37792a90\">\n   <rect height=\"217.44\" width=\"304.363636\" x=\"401.701989\" y=\"7.206946\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# training result\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
    "plt.plot(history.history['mlm_loss'], 'r--', label='mlm_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
    "plt.plot(history.history['mlm_lm_acc'], 'k--', label='mlm_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ]
}