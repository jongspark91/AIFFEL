{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('aiffel': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4c90d37bfa0f6cee7230e0ca7c4fe4973eec2558a701045cc616562c2e060e72"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# MemN QA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['은경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.getenv('HOME')+'/aiffel/babi_memory_net'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = os.path.join(home_dir, \"qa1_single-supporting-fact_train_kor.txt\")\n",
    "TEST_FILE = os.path.join(home_dir, \"qa1_single-supporting-fact_test_kor.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 필웅이는 화장실로 갔습니다.\n2 은경이는 복도로 이동했습니다.\n3 필웅이는 어디야? \t화장실\t1\n4 수종이는 복도로 복귀했습니다.\n5 경임이는 정원으로 갔습니다.\n6 수종이는 어디야? \t복도\t4\n7 은경이는 사무실로 갔습니다.\n8 경임이는 화장실로 뛰어갔습니다.\n9 수종이는 어디야? \t복도\t4\n10 필웅이는 복도로 갔습니다.\n11 수종이는 사무실로 가버렸습니다.\n12 수종이는 어디야? \t사무실\t11\n13 은경이는 정원으로 복귀했습니다.\n14 은경이는 침실로 갔습니다.\n15 경임이는 어디야? \t화장실\t8\n1 경임이는 사무실로 가버렸습니다.\n2 경임이는 화장실로 이동했습니다.\n3 경임이는 어디야? \t화장실\t2\n4 필웅이는 침실로 이동했습니다.\n5 수종이는 복도로 갔습니다.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "lines = open(TRAIN_FILE , \"rb\")\n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()\n",
    "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "source": [
    "## 데이터 전처리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "        \n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train 스토리 개수: 10000\ntrain 질문 개수: 10000\ntrain 답변 개수: 10000\ntest 스토리 개수: 1000\ntest 질문 개수: 1000\ntest 답변 개수: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"train 스토리 개수:\", len(train_stories))\n",
    "print(\"train 질문 개수:\", len(train_questions))\n",
    "print(\"train 답변 개수:\", len(train_answers))\n",
    "print(\"test 스토리 개수:\", len(test_stories))\n",
    "print(\"test 질문 개수:\", len(test_questions))\n",
    "print(\"test 답변 개수:\", len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['수종이는 화장실로 뛰어갔습니다.',\n",
       " '경임이는 사무실로 갔습니다.',\n",
       " '은경이는 부엌으로 이동했습니다.',\n",
       " '경임이는 화장실로 갔습니다.',\n",
       " '수종이는 복도로 갔습니다.',\n",
       " '필웅이는 부엌으로 가버렸습니다.',\n",
       " '수종이는 부엌으로 이동했습니다.',\n",
       " '수종이는 화장실로 가버렸습니다.']"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "train_stories[3878]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['필웅이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '경임이는 어디야? ']"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "train_questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['화장실', '복도', '복도', '사무실', '화장실']"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "train_answers[:5]"
   ]
  },
  {
   "source": [
    "## 토큰화 함수"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [ x.strip() for x in re.sub(r\"\\s+|\\b\", '\\f', sent).split('\\f') if x.strip() ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "    \n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "    \n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어장 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'.': 1, '경임이는': 2, '은경이는': 3, '수종이는': 4, '필웅이는': 5, '이동했습니다': 6, '가버렸습니다': 7, '뛰어갔습니다': 8, '복귀했습니다': 9, '갔습니다': 10, '화장실로': 11, '정원으로': 12, '복도로': 13, '어디야': 14, '?': 15, '부엌으로': 16, '사무실로': 17, '침실로': 18, '화장실': 19, '정원': 20, '사무실': 21, '침실': 22, '복도': 23, '부엌': 24}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "스토리의 최대 길이 : 40\n질문의 최대 길이 : 3\n"
     ]
    }
   ],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "        # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "        # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10000, 40) (10000, 3) (10000, 25) (1000, 40) (1000, 3) (1000, 25)\n"
     ]
    }
   ],
   "source": [
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "source": [
    "## 메모리 네트워크로 QA태스크 풀기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크 횟수\n",
    "train_epochs = 120\n",
    "# 배치 크기\n",
    "batch_size = 32\n",
    "# 임베딩 크기\n",
    "embed_size = 50\n",
    "# LSTM의 크기\n",
    "lstm_size = 64\n",
    "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
    "dropout_rate = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stories : Tensor(\"input_1:0\", shape=(None, 40), dtype=float32)\nQuestion: Tensor(\"input_2:0\", shape=(None, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 플레이스 홀더. 입력을 담는 변수\n",
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    "\n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embedding_dim) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    "\n",
    "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embedding_dim) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input encoded m Tensor(\"sequential/Identity:0\", shape=(None, 40, 50), dtype=float32)\nInput encoded c Tensor(\"sequential_1/Identity:0\", shape=(None, 40, 3), dtype=float32)\nQuestion encoded Tensor(\"sequential_2/Identity:0\", shape=(None, 3, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "print('Question encoded', question_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Match shape Tensor(\"activation/Identity:0\", shape=(None, 40, 3), dtype=float32)\nResponse shape Tensor(\"permute/Identity:0\", shape=(None, 3, 40), dtype=float32)\nAnswer shape Tensor(\"concatenate/Identity:0\", shape=(None, 3, 90), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_maxlen, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이\n",
    "\n",
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_max_len, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_max_len)\n",
    "print('Response shape', response)\n",
    "\n",
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    "\n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         multiple             1250        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 3, 50)        1250        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 40, 3)        0           sequential[1][0]                 \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 40, 3)        0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             75          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 40, 3)        0           activation[0][0]                 \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 3, 40)        0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 90)        0           permute[0][0]                    \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           39680       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 25)           1625        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 25)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 43,880\n",
      "Trainable params: 43,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.8999 - acc: 0.1707 - val_loss: 1.7816 - val_acc: 0.1830\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 1.6740 - acc: 0.2967 - val_loss: 1.5122 - val_acc: 0.4210\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.5134 - acc: 0.3968 - val_loss: 1.4882 - val_acc: 0.4120\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4910 - acc: 0.4088 - val_loss: 1.4645 - val_acc: 0.4180\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4488 - acc: 0.4348 - val_loss: 1.3947 - val_acc: 0.4600\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.4071 - acc: 0.4550 - val_loss: 1.3848 - val_acc: 0.4490\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3783 - acc: 0.4611 - val_loss: 1.3514 - val_acc: 0.4860\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3624 - acc: 0.4725 - val_loss: 1.3477 - val_acc: 0.4880\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3397 - acc: 0.4886 - val_loss: 1.3225 - val_acc: 0.4990\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.3265 - acc: 0.4916 - val_loss: 1.2940 - val_acc: 0.4950\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3145 - acc: 0.4968 - val_loss: 1.2906 - val_acc: 0.5020\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 1.2928 - acc: 0.5018 - val_loss: 1.2620 - val_acc: 0.5190\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2785 - acc: 0.5067 - val_loss: 1.2452 - val_acc: 0.5230\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2686 - acc: 0.5096 - val_loss: 1.2279 - val_acc: 0.5320\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2495 - acc: 0.5183 - val_loss: 1.2184 - val_acc: 0.5280\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2351 - acc: 0.5148 - val_loss: 1.2154 - val_acc: 0.5190\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2258 - acc: 0.5141 - val_loss: 1.2103 - val_acc: 0.5360\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2198 - acc: 0.5179 - val_loss: 1.2021 - val_acc: 0.5290\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1991 - acc: 0.5184 - val_loss: 1.1992 - val_acc: 0.5270\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1981 - acc: 0.5226 - val_loss: 1.1863 - val_acc: 0.5210\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1891 - acc: 0.5205 - val_loss: 1.1679 - val_acc: 0.5380\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1745 - acc: 0.5289 - val_loss: 1.1832 - val_acc: 0.5330\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1573 - acc: 0.5460 - val_loss: 1.1386 - val_acc: 0.5660\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1239 - acc: 0.5636 - val_loss: 1.1224 - val_acc: 0.5870\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0987 - acc: 0.5790 - val_loss: 1.0813 - val_acc: 0.6200\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0670 - acc: 0.6063 - val_loss: 1.0118 - val_acc: 0.6610\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.9965 - acc: 0.6359 - val_loss: 0.9186 - val_acc: 0.7020\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.9152 - acc: 0.6810 - val_loss: 0.8384 - val_acc: 0.7300\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8432 - acc: 0.7028 - val_loss: 0.7927 - val_acc: 0.7340\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.7798 - acc: 0.7253 - val_loss: 0.7349 - val_acc: 0.7430\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.7251 - acc: 0.7477 - val_loss: 0.6564 - val_acc: 0.7740\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6816 - acc: 0.7587 - val_loss: 0.6308 - val_acc: 0.7790\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6446 - acc: 0.7710 - val_loss: 0.6003 - val_acc: 0.7850\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6070 - acc: 0.7838 - val_loss: 0.6132 - val_acc: 0.7840\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.5663 - acc: 0.7972 - val_loss: 0.5461 - val_acc: 0.8030\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5414 - acc: 0.8081 - val_loss: 0.5031 - val_acc: 0.8150\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.5068 - acc: 0.8172 - val_loss: 0.4907 - val_acc: 0.8120\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4784 - acc: 0.8297 - val_loss: 0.4606 - val_acc: 0.8240\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4538 - acc: 0.8379 - val_loss: 0.4874 - val_acc: 0.8240\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4401 - acc: 0.8399 - val_loss: 0.4126 - val_acc: 0.8500\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4248 - acc: 0.8468 - val_loss: 0.4200 - val_acc: 0.8370\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4049 - acc: 0.8494 - val_loss: 0.3968 - val_acc: 0.8560\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3935 - acc: 0.8528 - val_loss: 0.3881 - val_acc: 0.8580\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.3869 - acc: 0.8561 - val_loss: 0.3854 - val_acc: 0.8540\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3779 - acc: 0.8603 - val_loss: 0.3795 - val_acc: 0.8540\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.3683 - acc: 0.8634 - val_loss: 0.3938 - val_acc: 0.8500\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3626 - acc: 0.8641 - val_loss: 0.3611 - val_acc: 0.8600\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3443 - acc: 0.8730 - val_loss: 0.3555 - val_acc: 0.8620\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3413 - acc: 0.8725 - val_loss: 0.3526 - val_acc: 0.8650\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.3370 - acc: 0.8731 - val_loss: 0.3647 - val_acc: 0.8600\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3309 - acc: 0.8777 - val_loss: 0.3589 - val_acc: 0.8610\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3233 - acc: 0.8774 - val_loss: 0.3582 - val_acc: 0.8600\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3183 - acc: 0.8819 - val_loss: 0.3443 - val_acc: 0.8660\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3136 - acc: 0.8814 - val_loss: 0.3444 - val_acc: 0.8630\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.3030 - acc: 0.8883 - val_loss: 0.3363 - val_acc: 0.8750\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3040 - acc: 0.8855 - val_loss: 0.3525 - val_acc: 0.8630\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2984 - acc: 0.8870 - val_loss: 0.3309 - val_acc: 0.8750\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2871 - acc: 0.8949 - val_loss: 0.3310 - val_acc: 0.8790\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2840 - acc: 0.8928 - val_loss: 0.3364 - val_acc: 0.8780\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.2824 - acc: 0.8971 - val_loss: 0.3424 - val_acc: 0.8670\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2698 - acc: 0.8986 - val_loss: 0.3194 - val_acc: 0.8810\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2718 - acc: 0.8999 - val_loss: 0.3188 - val_acc: 0.8830\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2653 - acc: 0.9030 - val_loss: 0.3131 - val_acc: 0.8870\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2517 - acc: 0.9067 - val_loss: 0.3221 - val_acc: 0.8740\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2559 - acc: 0.9027 - val_loss: 0.3034 - val_acc: 0.8920\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2389 - acc: 0.9130 - val_loss: 0.3011 - val_acc: 0.8890\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2385 - acc: 0.9102 - val_loss: 0.3040 - val_acc: 0.8930\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2464 - acc: 0.9084 - val_loss: 0.3032 - val_acc: 0.8890\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2275 - acc: 0.9171 - val_loss: 0.2822 - val_acc: 0.9030\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2264 - acc: 0.9174 - val_loss: 0.2987 - val_acc: 0.8850\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2182 - acc: 0.9230 - val_loss: 0.2832 - val_acc: 0.9000\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2177 - acc: 0.9231 - val_loss: 0.2737 - val_acc: 0.9020\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2127 - acc: 0.9227 - val_loss: 0.2743 - val_acc: 0.9000\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2051 - acc: 0.9244 - val_loss: 0.2794 - val_acc: 0.9010\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2096 - acc: 0.9254 - val_loss: 0.2758 - val_acc: 0.9030\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1989 - acc: 0.9285 - val_loss: 0.2884 - val_acc: 0.8990\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1919 - acc: 0.9299 - val_loss: 0.2546 - val_acc: 0.9100\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1876 - acc: 0.9328 - val_loss: 0.2645 - val_acc: 0.9070\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1799 - acc: 0.9328 - val_loss: 0.2570 - val_acc: 0.9100\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1789 - acc: 0.9360 - val_loss: 0.2593 - val_acc: 0.9180\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.1686 - acc: 0.9385 - val_loss: 0.2510 - val_acc: 0.9170\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1718 - acc: 0.9381 - val_loss: 0.2434 - val_acc: 0.9160\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1621 - acc: 0.9445 - val_loss: 0.2376 - val_acc: 0.9200\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1571 - acc: 0.9449 - val_loss: 0.2428 - val_acc: 0.9170\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1497 - acc: 0.9481 - val_loss: 0.2454 - val_acc: 0.9160\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1523 - acc: 0.9448 - val_loss: 0.2440 - val_acc: 0.9200\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1497 - acc: 0.9490 - val_loss: 0.2248 - val_acc: 0.9290\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1426 - acc: 0.9505 - val_loss: 0.2253 - val_acc: 0.9260\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1382 - acc: 0.9500 - val_loss: 0.2296 - val_acc: 0.9290\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.1366 - acc: 0.9517 - val_loss: 0.2502 - val_acc: 0.9270\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1312 - acc: 0.9523 - val_loss: 0.2210 - val_acc: 0.9320\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1198 - acc: 0.9584 - val_loss: 0.2282 - val_acc: 0.9270\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1274 - acc: 0.9550 - val_loss: 0.2430 - val_acc: 0.9190\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.1147 - acc: 0.9586 - val_loss: 0.2198 - val_acc: 0.9410\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1155 - acc: 0.9591 - val_loss: 0.2042 - val_acc: 0.9330\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1171 - acc: 0.9625 - val_loss: 0.2080 - val_acc: 0.9370\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1127 - acc: 0.9610 - val_loss: 0.2371 - val_acc: 0.9290\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1088 - acc: 0.9591 - val_loss: 0.2210 - val_acc: 0.9330\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.1092 - acc: 0.9599 - val_loss: 0.2197 - val_acc: 0.9280\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1068 - acc: 0.9635 - val_loss: 0.2059 - val_acc: 0.9340\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.1005 - acc: 0.9633 - val_loss: 0.2216 - val_acc: 0.9300\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0987 - acc: 0.9673 - val_loss: 0.2185 - val_acc: 0.9380\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1027 - acc: 0.9622 - val_loss: 0.2132 - val_acc: 0.9420\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0876 - acc: 0.9692 - val_loss: 0.2148 - val_acc: 0.9420\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0915 - acc: 0.9669 - val_loss: 0.2255 - val_acc: 0.9350\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0927 - acc: 0.9685 - val_loss: 0.2186 - val_acc: 0.9330\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0910 - acc: 0.9692 - val_loss: 0.2033 - val_acc: 0.9350\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0919 - acc: 0.9700 - val_loss: 0.2012 - val_acc: 0.9380\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0840 - acc: 0.9699 - val_loss: 0.2111 - val_acc: 0.9410\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0815 - acc: 0.9717 - val_loss: 0.2302 - val_acc: 0.9380\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0841 - acc: 0.9675 - val_loss: 0.1936 - val_acc: 0.9470\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0767 - acc: 0.9748 - val_loss: 0.2123 - val_acc: 0.9460\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0819 - acc: 0.9719 - val_loss: 0.2022 - val_acc: 0.9470\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0855 - acc: 0.9711 - val_loss: 0.2201 - val_acc: 0.9430\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0761 - acc: 0.9738 - val_loss: 0.2085 - val_acc: 0.9430\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0828 - acc: 0.9723 - val_loss: 0.2028 - val_acc: 0.9410\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0794 - acc: 0.9727 - val_loss: 0.1979 - val_acc: 0.9450\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0738 - acc: 0.9752 - val_loss: 0.2213 - val_acc: 0.9390\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0684 - acc: 0.9774 - val_loss: 0.2159 - val_acc: 0.9370\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0682 - acc: 0.9773 - val_loss: 0.2240 - val_acc: 0.9400\n"
     ]
    }
   ],
   "source": [
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# start training the model\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    "\n",
    "# save model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2240 - acc: 0.9400\n",
      "\n",
      " 테스트 정확도: 0.9400\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"279.59625pt\" version=\"1.1\" viewBox=\"0 0 424.690625 279.59625\" width=\"424.690625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-05-11T22:22:50.097631</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 279.59625 \nL 424.690625 279.59625 \nL 424.690625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 117.118125 \nL 417.490625 117.118125 \nL 417.490625 22.318125 \nL 36.465625 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m5a354b3314\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"53.784943\" xlink:href=\"#m5a354b3314\" y=\"117.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(50.603693 131.716563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"112.001139\" xlink:href=\"#m5a354b3314\" y=\"117.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <g transform=\"translate(105.638639 131.716563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"170.217334\" xlink:href=\"#m5a354b3314\" y=\"117.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <g transform=\"translate(163.854834 131.716563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"228.43353\" xlink:href=\"#m5a354b3314\" y=\"117.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <g transform=\"translate(222.07103 131.716563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"286.649725\" xlink:href=\"#m5a354b3314\" y=\"117.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <g transform=\"translate(280.287225 131.716563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"344.865921\" xlink:href=\"#m5a354b3314\" y=\"117.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <g transform=\"translate(335.322171 131.716563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"403.082117\" xlink:href=\"#m5a354b3314\" y=\"117.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120 -->\n      <g transform=\"translate(393.538367 131.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m2f43022b76\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2f43022b76\" y=\"104.337213\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.25 -->\n      <g transform=\"translate(7.2 108.136432)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2f43022b76\" y=\"77.629075\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.50 -->\n      <g transform=\"translate(7.2 81.428294)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2f43022b76\" y=\"50.920938\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.75 -->\n      <g transform=\"translate(7.2 54.720157)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2f43022b76\" y=\"24.212801\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.00 -->\n      <g transform=\"translate(7.2 28.01202)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#p7546121d3d)\" d=\"M 53.784943 112.809034 \nL 56.695753 99.348133 \nL 59.606563 88.654193 \nL 62.517373 87.372203 \nL 65.428182 84.594558 \nL 68.338992 82.436539 \nL 71.249802 81.78486 \nL 74.160612 80.566971 \nL 77.071421 78.846968 \nL 79.982231 78.526468 \nL 82.893041 77.970939 \nL 85.803851 77.436777 \nL 88.714661 76.9133 \nL 91.62547 76.603485 \nL 94.53628 75.67404 \nL 97.44709 76.047952 \nL 100.3579 76.122735 \nL 103.268709 75.716774 \nL 106.179519 75.663355 \nL 109.090329 75.21466 \nL 112.001139 75.439008 \nL 114.911949 74.541612 \nL 117.822758 72.714778 \nL 120.733568 70.834525 \nL 123.644378 69.189304 \nL 126.555188 66.272776 \nL 129.465997 63.11053 \nL 132.376807 58.292385 \nL 135.287617 55.963437 \nL 138.198427 53.559701 \nL 141.109237 51.166656 \nL 144.020046 49.991494 \nL 146.930856 48.677452 \nL 149.841666 47.309997 \nL 152.752476 45.878439 \nL 155.663285 44.713969 \nL 158.574095 43.74179 \nL 161.484905 42.406385 \nL 164.395715 41.530359 \nL 167.306525 41.31669 \nL 170.217334 40.579544 \nL 173.128144 40.301784 \nL 176.038954 39.938551 \nL 178.949764 39.586002 \nL 181.860573 39.137307 \nL 184.771383 38.806129 \nL 187.682193 38.731346 \nL 190.593003 37.780532 \nL 193.503813 37.833951 \nL 196.414622 37.769853 \nL 199.325432 37.278425 \nL 202.236242 37.310473 \nL 205.147052 36.829724 \nL 208.057861 36.883142 \nL 210.968671 36.145996 \nL 213.879481 36.445126 \nL 216.790291 36.284876 \nL 219.701101 35.440899 \nL 222.61191 35.665253 \nL 225.52272 35.205873 \nL 228.43353 35.045623 \nL 231.34434 34.906737 \nL 234.255149 34.575558 \nL 237.165959 34.180276 \nL 240.076769 34.607607 \nL 242.987579 33.507234 \nL 245.898389 33.806364 \nL 248.809198 33.998662 \nL 251.720008 33.069218 \nL 254.630818 33.037169 \nL 257.541628 32.438909 \nL 260.452437 32.428224 \nL 263.363247 32.470958 \nL 266.274057 32.289345 \nL 269.184867 32.182507 \nL 272.095677 31.851328 \nL 275.006486 31.701764 \nL 277.917296 31.391949 \nL 280.828106 31.391949 \nL 283.738916 31.050085 \nL 286.649725 30.783004 \nL 289.560535 30.825738 \nL 292.471345 30.142004 \nL 295.382155 30.099277 \nL 298.292965 29.757413 \nL 301.203774 30.109955 \nL 304.114584 29.661261 \nL 307.025394 29.501011 \nL 309.936204 29.55443 \nL 312.847013 29.372816 \nL 315.757823 29.308712 \nL 318.668633 28.657034 \nL 321.579443 29.020267 \nL 324.490253 28.63567 \nL 327.401062 28.582251 \nL 330.311872 28.219024 \nL 333.222682 28.379268 \nL 336.133492 28.582251 \nL 339.044301 28.496784 \nL 341.955111 28.112186 \nL 344.865921 28.133556 \nL 347.776731 27.706225 \nL 350.687541 28.251073 \nL 353.59835 27.503242 \nL 356.50916 27.748959 \nL 359.41997 27.578024 \nL 362.33078 27.503242 \nL 365.241589 27.417774 \nL 368.152399 27.428459 \nL 371.063209 27.236161 \nL 373.974019 27.684862 \nL 376.884829 26.904982 \nL 379.795638 27.214797 \nL 382.706448 27.300264 \nL 385.617258 27.011813 \nL 388.528068 27.172063 \nL 391.438877 27.129329 \nL 394.349687 26.862248 \nL 397.260497 26.627216 \nL 400.171307 26.637901 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#p7546121d3d)\" d=\"M 53.784943 111.494994 \nL 56.695753 86.068846 \nL 59.606563 87.03034 \nL 62.517373 86.389343 \nL 65.428182 81.902377 \nL 68.338992 83.077535 \nL 71.249802 79.124731 \nL 74.160612 78.911065 \nL 77.071421 77.735907 \nL 79.982231 78.163238 \nL 82.893041 77.415413 \nL 85.803851 75.599258 \nL 88.714661 75.171927 \nL 91.62547 74.210433 \nL 94.53628 74.637764 \nL 97.44709 75.599258 \nL 100.3579 73.783102 \nL 103.268709 74.530933 \nL 106.179519 74.744596 \nL 109.090329 75.385589 \nL 112.001139 73.56944 \nL 114.911949 74.103602 \nL 117.822758 70.578129 \nL 120.733568 68.334642 \nL 123.644378 64.809169 \nL 126.555188 60.429034 \nL 129.465997 56.048898 \nL 132.376807 53.057587 \nL 135.287617 52.630256 \nL 138.198427 51.668769 \nL 141.109237 48.356958 \nL 144.020046 47.822796 \nL 146.930856 47.181796 \nL 149.841666 47.288634 \nL 152.752476 45.258816 \nL 155.663285 43.976823 \nL 158.574095 44.297323 \nL 161.484905 43.015329 \nL 164.395715 43.015329 \nL 167.306525 40.237681 \nL 170.217334 41.626505 \nL 173.128144 39.596687 \nL 176.038954 39.383025 \nL 178.949764 39.810356 \nL 181.860573 39.810356 \nL 184.771383 40.237681 \nL 187.682193 39.169356 \nL 190.593003 38.955694 \nL 193.503813 38.635194 \nL 196.414622 39.169356 \nL 199.325432 39.062525 \nL 202.236242 39.169356 \nL 205.147052 38.528363 \nL 208.057861 38.848863 \nL 210.968671 37.566869 \nL 213.879481 38.848863 \nL 216.790291 37.566869 \nL 219.701101 37.139538 \nL 222.61191 37.24637 \nL 225.52272 38.421532 \nL 228.43353 36.925876 \nL 231.34434 36.712207 \nL 234.255149 36.284876 \nL 237.165959 37.673701 \nL 240.076769 35.750714 \nL 242.987579 36.071214 \nL 245.898389 35.643883 \nL 248.809198 36.071214 \nL 251.720008 34.575558 \nL 254.630818 36.498545 \nL 257.541628 34.896058 \nL 260.452437 34.68239 \nL 263.363247 34.896058 \nL 266.274057 34.789221 \nL 269.184867 34.575558 \nL 272.095677 35.002889 \nL 275.006486 33.827727 \nL 277.917296 34.148227 \nL 280.828106 33.827727 \nL 283.738916 32.973072 \nL 286.649725 33.079903 \nL 289.560535 33.186734 \nL 292.471345 32.759403 \nL 295.382155 33.079903 \nL 298.292965 33.186734 \nL 301.203774 32.759403 \nL 304.114584 31.79791 \nL 307.025394 32.11841 \nL 309.936204 31.79791 \nL 312.847013 32.011578 \nL 315.757823 31.477416 \nL 318.668633 32.011578 \nL 321.579443 32.866234 \nL 324.490253 30.515923 \nL 327.401062 31.370579 \nL 330.311872 30.943254 \nL 333.222682 31.79791 \nL 336.133492 31.370579 \nL 339.044301 31.904747 \nL 341.955111 31.263747 \nL 344.865921 31.691079 \nL 347.776731 30.836416 \nL 350.687541 30.409092 \nL 353.59835 30.409092 \nL 356.50916 31.156916 \nL 359.41997 31.370579 \nL 362.33078 31.156916 \nL 365.241589 30.836416 \nL 368.152399 30.515923 \nL 371.063209 30.836416 \nL 373.974019 29.874923 \nL 376.884829 29.981761 \nL 379.795638 29.874923 \nL 382.706448 30.302254 \nL 385.617258 30.302254 \nL 388.528068 30.515923 \nL 391.438877 30.088592 \nL 394.349687 30.729585 \nL 397.260497 30.943254 \nL 400.171307 30.622754 \n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 117.118125 \nL 36.465625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 417.490625 117.118125 \nL 417.490625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 117.118125 \nL 417.490625 117.118125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 22.318125 \nL 417.490625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_12\">\n    <!-- Accuracy -->\n    <g transform=\"translate(199.584375 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"121.638672\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"176.619141\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"239.998047\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"281.111328\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"342.390625\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"397.371094\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 43.465625 59.674375 \nL 124.7 59.674375 \nQ 126.7 59.674375 126.7 57.674375 \nL 126.7 29.318125 \nQ 126.7 27.318125 124.7 27.318125 \nL 43.465625 27.318125 \nQ 41.465625 27.318125 41.465625 29.318125 \nL 41.465625 57.674375 \nQ 41.465625 59.674375 43.465625 59.674375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_14\">\n     <path d=\"M 45.465625 35.416562 \nL 65.465625 35.416562 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_15\"/>\n    <g id=\"text_13\">\n     <!-- train -->\n     <g transform=\"translate(73.465625 38.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 45.465625 50.094687 \nL 65.465625 50.094687 \n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_17\"/>\n    <g id=\"text_14\">\n     <!-- validation -->\n     <g transform=\"translate(73.465625 53.594687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n       <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"176.025391\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"239.501953\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"300.78125\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"339.990234\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"367.773438\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"428.955078\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 36.465625 255.718125 \nL 417.490625 255.718125 \nL 417.490625 160.918125 \nL 36.465625 160.918125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_8\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"53.784943\" xlink:href=\"#m5a354b3314\" y=\"255.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0 -->\n      <g transform=\"translate(50.603693 270.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"112.001139\" xlink:href=\"#m5a354b3314\" y=\"255.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 20 -->\n      <g transform=\"translate(105.638639 270.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"170.217334\" xlink:href=\"#m5a354b3314\" y=\"255.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 40 -->\n      <g transform=\"translate(163.854834 270.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"228.43353\" xlink:href=\"#m5a354b3314\" y=\"255.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 60 -->\n      <g transform=\"translate(222.07103 270.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"286.649725\" xlink:href=\"#m5a354b3314\" y=\"255.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 80 -->\n      <g transform=\"translate(280.287225 270.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_23\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"344.865921\" xlink:href=\"#m5a354b3314\" y=\"255.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 100 -->\n      <g transform=\"translate(335.322171 270.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"403.082117\" xlink:href=\"#m5a354b3314\" y=\"255.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 120 -->\n      <g transform=\"translate(393.538367 270.316563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_5\">\n     <g id=\"line2d_25\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2f43022b76\" y=\"254.616142\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 0 -->\n      <g transform=\"translate(23.103125 258.41536)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2f43022b76\" y=\"207.567732\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 1 -->\n      <g transform=\"translate(23.103125 211.366951)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_27\">\n    <path clip-path=\"url(#p5351c17b43)\" d=\"M 53.784943 165.227216 \nL 56.695753 175.858769 \nL 59.606563 183.413384 \nL 62.517373 184.466501 \nL 65.428182 186.453608 \nL 68.338992 188.416132 \nL 71.249802 189.767897 \nL 74.160612 190.51853 \nL 77.071421 191.583846 \nL 79.982231 192.204466 \nL 82.893041 192.77328 \nL 85.803851 193.791052 \nL 88.714661 194.46275 \nL 91.62547 194.932336 \nL 94.53628 195.829898 \nL 97.44709 196.507648 \nL 100.3579 196.944329 \nL 103.268709 197.225157 \nL 106.179519 198.198329 \nL 109.090329 198.246042 \nL 112.001139 198.673109 \nL 114.911949 199.358251 \nL 117.822758 200.165369 \nL 120.733568 201.736704 \nL 123.644378 202.923519 \nL 126.555188 204.417596 \nL 129.465997 207.733164 \nL 132.376807 211.557684 \nL 135.287617 214.944638 \nL 138.198427 217.927531 \nL 141.109237 220.50138 \nL 144.020046 222.548253 \nL 146.930856 224.28811 \nL 149.841666 226.05716 \nL 152.752476 227.972564 \nL 155.663285 229.142301 \nL 158.574095 230.771049 \nL 161.484905 232.107136 \nL 164.395715 233.265766 \nL 167.306525 233.908087 \nL 170.217334 234.628876 \nL 173.128144 235.566879 \nL 176.038954 236.103409 \nL 178.949764 236.415413 \nL 181.860573 236.836578 \nL 184.771383 237.285947 \nL 187.682193 237.557458 \nL 190.593003 238.417836 \nL 193.503813 238.559237 \nL 196.414622 238.760207 \nL 199.325432 239.049328 \nL 202.236242 239.407727 \nL 205.147052 239.641747 \nL 208.057861 239.864093 \nL 210.968671 240.359129 \nL 213.879481 240.314016 \nL 216.790291 240.578725 \nL 219.701101 241.110811 \nL 222.61191 241.253693 \nL 225.52272 241.328929 \nL 228.43353 241.923949 \nL 231.34434 241.829546 \nL 234.255149 242.132932 \nL 237.165959 242.773438 \nL 240.076769 242.57464 \nL 242.987579 243.376186 \nL 245.898389 243.395445 \nL 248.809198 243.025195 \nL 251.720008 243.912909 \nL 254.630818 243.963323 \nL 257.541628 244.350492 \nL 260.452437 244.373893 \nL 263.363247 244.610416 \nL 266.274057 244.966626 \nL 269.184867 244.755397 \nL 272.095677 245.259553 \nL 275.006486 245.586189 \nL 277.917296 245.788309 \nL 280.828106 246.152211 \nL 283.738916 246.199068 \nL 286.649725 246.682148 \nL 289.560535 246.531397 \nL 292.471345 246.989003 \nL 295.382155 247.225348 \nL 298.292965 247.574815 \nL 301.203774 247.451882 \nL 304.114584 247.573262 \nL 307.025394 247.908233 \nL 309.936204 248.113015 \nL 312.847013 248.189692 \nL 315.757823 248.442924 \nL 318.668633 248.978748 \nL 321.579443 248.620731 \nL 324.490253 249.21981 \nL 327.401062 249.180007 \nL 330.311872 249.106113 \nL 333.222682 249.315045 \nL 336.133492 249.497583 \nL 339.044301 249.47678 \nL 341.955111 249.592101 \nL 344.865921 249.886542 \nL 347.776731 249.970821 \nL 350.687541 249.784821 \nL 353.59835 250.495549 \nL 356.50916 250.309081 \nL 359.41997 250.256003 \nL 362.33078 250.3367 \nL 365.241589 250.291161 \nL 368.152399 250.664887 \nL 371.063209 250.780319 \nL 373.974019 250.658894 \nL 376.884829 251.009183 \nL 379.795638 250.762036 \nL 382.706448 250.59401 \nL 385.617258 251.037592 \nL 388.528068 250.721916 \nL 391.438877 250.879846 \nL 394.349687 251.141817 \nL 397.260497 251.396522 \nL 400.171307 251.409034 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path clip-path=\"url(#p5351c17b43)\" d=\"M 53.784943 170.796883 \nL 56.695753 183.46924 \nL 59.606563 184.596654 \nL 62.517373 185.714506 \nL 65.428182 188.998794 \nL 68.338992 189.465828 \nL 71.249802 191.035089 \nL 74.160612 191.20697 \nL 77.071421 192.395737 \nL 79.982231 193.734315 \nL 82.893041 193.895164 \nL 85.803851 195.241572 \nL 88.714661 196.030019 \nL 91.62547 196.846335 \nL 94.53628 197.293184 \nL 97.44709 197.432019 \nL 100.3579 197.671103 \nL 103.268709 198.059729 \nL 106.179519 198.197802 \nL 109.090329 198.803767 \nL 112.001139 199.669388 \nL 114.911949 198.948693 \nL 117.822758 201.047625 \nL 120.733568 201.810227 \nL 123.644378 203.743907 \nL 126.555188 207.011196 \nL 129.465997 211.399558 \nL 132.376807 215.170875 \nL 135.287617 217.320279 \nL 138.198427 220.039419 \nL 141.109237 223.73242 \nL 144.020046 224.936358 \nL 146.930856 226.372095 \nL 149.841666 225.767588 \nL 152.752476 228.921229 \nL 155.663285 230.944049 \nL 158.574095 231.529403 \nL 161.484905 232.944302 \nL 164.395715 231.682589 \nL 167.306525 235.204753 \nL 170.217334 234.856468 \nL 173.128144 235.946279 \nL 176.038954 236.355392 \nL 178.949764 236.4844 \nL 181.860573 236.759268 \nL 184.771383 236.086347 \nL 187.682193 237.628294 \nL 190.593003 237.89251 \nL 193.503813 238.024559 \nL 196.414622 237.455854 \nL 199.325432 237.729633 \nL 202.236242 237.763735 \nL 205.147052 238.416541 \nL 208.057861 238.411803 \nL 210.968671 238.792371 \nL 213.879481 238.033329 \nL 216.790291 239.049871 \nL 219.701101 239.044874 \nL 222.61191 238.787533 \nL 225.52272 238.506105 \nL 228.43353 239.586594 \nL 231.34434 239.61528 \nL 234.255149 239.885797 \nL 237.165959 239.461226 \nL 240.076769 240.342876 \nL 242.987579 240.450719 \nL 245.898389 240.311355 \nL 248.809198 240.351581 \nL 251.720008 241.338402 \nL 254.630818 240.562368 \nL 257.541628 241.293108 \nL 260.452437 241.737439 \nL 263.363247 241.711258 \nL 266.274057 241.468524 \nL 269.184867 241.642016 \nL 272.095677 241.048839 \nL 275.006486 242.63647 \nL 277.917296 242.172605 \nL 280.828106 242.522555 \nL 283.738916 242.418771 \nL 286.649725 242.805449 \nL 289.560535 243.164934 \nL 292.471345 243.43821 \nL 295.382155 243.194433 \nL 298.292965 243.069587 \nL 301.203774 243.137581 \nL 304.114584 244.038119 \nL 307.025394 244.016535 \nL 309.936204 243.813597 \nL 312.847013 242.845057 \nL 315.757823 244.218683 \nL 318.668633 243.882017 \nL 321.579443 243.185404 \nL 324.490253 244.2766 \nL 327.401062 245.008512 \nL 330.311872 244.831423 \nL 333.222682 243.460268 \nL 336.133492 244.219696 \nL 339.044301 244.278207 \nL 341.955111 244.927081 \nL 344.865921 244.189674 \nL 347.776731 244.334131 \nL 350.687541 244.587063 \nL 353.59835 244.508386 \nL 356.50916 244.006614 \nL 359.41997 244.332425 \nL 362.33078 245.051969 \nL 365.241589 245.149429 \nL 368.152399 244.682936 \nL 371.063209 243.786346 \nL 373.974019 245.506112 \nL 376.884829 244.629095 \nL 379.795638 245.103086 \nL 382.706448 244.263115 \nL 385.617258 244.807411 \nL 388.528068 245.07333 \nL 391.438877 245.304338 \nL 394.349687 244.203465 \nL 397.260497 244.459935 \nL 400.171307 244.079102 \n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 36.465625 255.718125 \nL 36.465625 160.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 417.490625 255.718125 \nL 417.490625 160.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 36.465625 255.718125 \nL 417.490625 255.718125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 36.465625 160.918125 \nL 417.490625 160.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_24\">\n    <!-- Loss -->\n    <g transform=\"translate(213.8175 154.918125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-76\"/>\n     <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_13\">\n     <path d=\"M 329.25625 198.274375 \nL 410.490625 198.274375 \nQ 412.490625 198.274375 412.490625 196.274375 \nL 412.490625 167.918125 \nQ 412.490625 165.918125 410.490625 165.918125 \nL 329.25625 165.918125 \nQ 327.25625 165.918125 327.25625 167.918125 \nL 327.25625 196.274375 \nQ 327.25625 198.274375 329.25625 198.274375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_29\">\n     <path d=\"M 331.25625 174.016563 \nL 351.25625 174.016563 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_30\"/>\n    <g id=\"text_25\">\n     <!-- train -->\n     <g transform=\"translate(359.25625 177.516563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_31\">\n     <path d=\"M 331.25625 188.694688 \nL 351.25625 188.694688 \n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_32\"/>\n    <g id=\"text_26\">\n     <!-- validation -->\n     <g transform=\"translate(359.25625 192.194688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"176.025391\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"239.501953\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"300.78125\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"339.990234\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"367.773438\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"428.955078\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7546121d3d\">\n   <rect height=\"94.8\" width=\"381.025\" x=\"36.465625\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p5351c17b43\">\n   <rect height=\"94.8\" width=\"381.025\" x=\"36.465625\" y=\"160.918125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}